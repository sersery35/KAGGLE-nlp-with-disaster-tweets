{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "\n",
    "log_dir = f'./logs/hyperparameter_tuning_BaseModel/'\n",
    "\n",
    "try:\n",
    "    # clearing logging directory\n",
    "    shutil.rmtree(log_dir)\n",
    "except NotADirectoryError:\n",
    "    pass\n",
    "\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-02 17:18:16.543595: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-02 17:18:16.543614: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from KAGGLE_NLP_with_disaster_tweets.model import base_model, utils, constants\n",
    "from KAGGLE_NLP_with_disaster_tweets.data_preparation.utils import DataPipeline, BatchPipeline\n",
    "\n",
    "from tensorboard import notebook"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_file_name = 'train.csv'\n",
    "test_file_name = 'test.csv'\n",
    "sample_submission_file_name = 'sample_submission.csv'\n",
    "output_sequence_length = 30"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-02 17:18:18.529469: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-03-02 17:18:18.529517: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: sersery-desktop\n",
      "2022-03-02 17:18:18.529523: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: sersery-desktop\n",
      "2022-03-02 17:18:18.529608: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 470.103.1\n",
      "2022-03-02 17:18:18.529630: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 470.103.1\n",
      "2022-03-02 17:18:18.529635: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 470.103.1\n",
      "2022-03-02 17:18:18.530017: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the file: ../data/train.csv\n",
      "-----------------------------------------------------------------------------------------\n",
      "Dataset \n",
      "Size: 7613\n",
      "Dataset examples:\n",
      "Input: [  15   37 3396    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "Target: [1. 0.]\n",
      "Input: [   1   13   96 2948    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "Target: [1. 0.]\n",
      "Input: [  31  437  210 1382    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "Target: [0. 1.]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Getting the file: ../data/test.csv\n",
      "Getting the file: ../data/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "max_vocabulary_size = 20000\n",
    "glove_embedding_dim = 200\n",
    "\n",
    "data_pipeline = DataPipeline(train_file_name, test_file_name, sample_submission_file_name,\n",
    "                             output_sequence_length=30,\n",
    "                             max_vocabulary_size=max_vocabulary_size,\n",
    "                             glove_embedding_dim=glove_embedding_dim,\n",
    "                             glove_url=constants.glove_url['twitter.27B'])\n",
    "dataset = data_pipeline.prepare_dataset(include_cols=[\"location\", \"keyword\"], apply_preprocessing=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "balanced_class_weights = utils.get_balanced_class_weights(data_pipeline.dataframe)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "log_directory = \"./logs/hyperparameter_tuning_BaseModel/\"\n",
    "utils.start_logging(log_directory, constants.hyperparameters, constants.metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, None, 64)         24832     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 16)          1040      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 16)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 16)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 345,906\n",
      "Trainable params: 345,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=1e-05__hidden_unit=16__batch_size=16__optimizer=adamw__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "333/333 [==============================] - 23s 54ms/step - loss: 0.7550 - accuracy: 0.5666 - val_loss: 0.7240 - val_accuracy: 0.5467\n",
      "Epoch 2/3\n",
      "333/333 [==============================] - 18s 50ms/step - loss: 0.7545 - accuracy: 0.5783 - val_loss: 0.7238 - val_accuracy: 0.5431\n",
      "Epoch 3/3\n",
      "333/333 [==============================] - 18s 53ms/step - loss: 0.7542 - accuracy: 0.5796 - val_loss: 0.7237 - val_accuracy: 0.5431\n",
      "71/71 [==============================] - 2s 15ms/step - loss: 0.7237 - accuracy: 0.5572\n",
      "run=0__lr=1e-05__hidden_unit=16__batch_size=16__optimizer=adamw__class_weights=balanced__dropout=0.1 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sersery/anaconda3/envs/tf-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, None, 64)         24832     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, None, 16)          1040      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, None, 16)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_1   (None, 16)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 345,906\n",
      "Trainable params: 345,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=1e-05__hidden_unit=16__batch_size=16__optimizer=adamw__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "333/333 [==============================] - 27s 62ms/step - loss: 0.7241 - accuracy: 0.4493 - val_loss: 0.7239 - val_accuracy: 0.4947\n",
      "Epoch 2/3\n",
      "333/333 [==============================] - 18s 52ms/step - loss: 0.7237 - accuracy: 0.4762 - val_loss: 0.7236 - val_accuracy: 0.5150\n",
      "Epoch 3/3\n",
      "333/333 [==============================] - 18s 51ms/step - loss: 0.7236 - accuracy: 0.4979 - val_loss: 0.7235 - val_accuracy: 0.5326\n",
      "71/71 [==============================] - 2s 14ms/step - loss: 0.7235 - accuracy: 0.5150\n",
      "run=0__lr=1e-05__hidden_unit=16__batch_size=16__optimizer=adamw__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, None, 64)         24832     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, None, 16)          1040      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, None, 16)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_2   (None, 16)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 345,906\n",
      "Trainable params: 345,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=1e-05__hidden_unit=16__batch_size=16__optimizer=adamw__class_weights=balanced__dropout=0.4 starting...\n",
      "Epoch 1/3\n",
      "333/333 [==============================] - 27s 61ms/step - loss: 0.7549 - accuracy: 0.5306 - val_loss: 0.7238 - val_accuracy: 0.5537\n",
      "Epoch 2/3\n",
      "333/333 [==============================] - 20s 58ms/step - loss: 0.7544 - accuracy: 0.5691 - val_loss: 0.7236 - val_accuracy: 0.5484\n",
      "Epoch 3/3\n",
      "333/333 [==============================] - 21s 61ms/step - loss: 0.7541 - accuracy: 0.5775 - val_loss: 0.7235 - val_accuracy: 0.5484\n",
      "71/71 [==============================] - 2s 16ms/step - loss: 0.7235 - accuracy: 0.5634\n",
      "run=0__lr=1e-05__hidden_unit=16__batch_size=16__optimizer=adamw__class_weights=balanced__dropout=0.4 completed.\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, None, 64)         24832     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, None, 16)          1040      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, None, 16)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_3   (None, 16)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 345,906\n",
      "Trainable params: 345,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=1e-05__hidden_unit=16__batch_size=16__optimizer=adamw__class_weights=none__dropout=0.4 starting...\n",
      "Epoch 1/3\n",
      "333/333 [==============================] - 31s 75ms/step - loss: 0.7241 - accuracy: 0.5023 - val_loss: 0.7239 - val_accuracy: 0.5396\n",
      "Epoch 2/3\n",
      "333/333 [==============================] - 26s 72ms/step - loss: 0.7237 - accuracy: 0.5358 - val_loss: 0.7237 - val_accuracy: 0.5264\n",
      "Epoch 3/3\n",
      "333/333 [==============================] - 28s 79ms/step - loss: 0.7236 - accuracy: 0.5501 - val_loss: 0.7236 - val_accuracy: 0.5317\n",
      "71/71 [==============================] - 3s 21ms/step - loss: 0.7236 - accuracy: 0.5563\n",
      "run=0__lr=1e-05__hidden_unit=16__batch_size=16__optimizer=adamw__class_weights=none__dropout=0.4 completed.\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, None, 64)         24832     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, None, 16)          1040      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, None, 16)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_4   (None, 16)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 345,906\n",
      "Trainable params: 345,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=16__optimizer=adamw__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "333/333 [==============================] - 35s 82ms/step - loss: 0.7059 - accuracy: 0.6139 - val_loss: 0.6621 - val_accuracy: 0.6646\n",
      "Epoch 2/3\n",
      "333/333 [==============================] - 26s 74ms/step - loss: 0.6265 - accuracy: 0.7840 - val_loss: 0.6453 - val_accuracy: 0.6998\n",
      "Epoch 3/3\n",
      "333/333 [==============================] - 28s 80ms/step - loss: 0.5977 - accuracy: 0.8465 - val_loss: 0.6427 - val_accuracy: 0.7077\n",
      "71/71 [==============================] - 3s 19ms/step - loss: 0.6375 - accuracy: 0.7174\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=16__optimizer=adamw__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, None, 64)         24832     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, None, 16)          1040      \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, None, 16)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_5   (None, 16)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 345,906\n",
      "Trainable params: 345,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=16__optimizer=adamw__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "333/333 [==============================] - 30s 73ms/step - loss: 0.6887 - accuracy: 0.6152 - val_loss: 0.6481 - val_accuracy: 0.6901\n",
      "Epoch 2/3\n",
      "333/333 [==============================] - 22s 62ms/step - loss: 0.6073 - accuracy: 0.7887 - val_loss: 0.6393 - val_accuracy: 0.7174\n",
      "Epoch 3/3\n",
      "333/333 [==============================] - 22s 63ms/step - loss: 0.5821 - accuracy: 0.8407 - val_loss: 0.6389 - val_accuracy: 0.7192\n",
      "71/71 [==============================] - 3s 21ms/step - loss: 0.6342 - accuracy: 0.7298\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=16__optimizer=adamw__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_6 (Bidirectio  (None, None, 64)         24832     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, None, 16)          1040      \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, None, 16)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_6   (None, 16)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 345,906\n",
      "Trainable params: 345,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=16__optimizer=adamw__class_weights=balanced__dropout=0.4 starting...\n",
      "Epoch 1/3\n",
      "333/333 [==============================] - 30s 70ms/step - loss: 0.7149 - accuracy: 0.5950 - val_loss: 0.6819 - val_accuracy: 0.6312\n",
      "Epoch 2/3\n",
      "333/333 [==============================] - 22s 63ms/step - loss: 0.6410 - accuracy: 0.7603 - val_loss: 0.6488 - val_accuracy: 0.6989\n",
      "Epoch 3/3\n",
      "333/333 [==============================] - 22s 64ms/step - loss: 0.6070 - accuracy: 0.8371 - val_loss: 0.6446 - val_accuracy: 0.7051\n",
      "71/71 [==============================] - 2s 17ms/step - loss: 0.6392 - accuracy: 0.7218\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=16__optimizer=adamw__class_weights=balanced__dropout=0.4 completed.\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (None, None, 64)         24832     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, None, 16)          1040      \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, None, 16)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_7   (None, 16)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 345,906\n",
      "Trainable params: 345,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=16__optimizer=adamw__class_weights=none__dropout=0.4 starting...\n",
      "Epoch 1/3\n",
      "333/333 [==============================] - 30s 72ms/step - loss: 0.6988 - accuracy: 0.6014 - val_loss: 0.6755 - val_accuracy: 0.6408\n",
      "Epoch 2/3\n",
      "333/333 [==============================] - 22s 63ms/step - loss: 0.6242 - accuracy: 0.7725 - val_loss: 0.6397 - val_accuracy: 0.7271\n",
      "Epoch 3/3\n",
      "333/333 [==============================] - 23s 65ms/step - loss: 0.5864 - accuracy: 0.8431 - val_loss: 0.6378 - val_accuracy: 0.7262\n",
      "71/71 [==============================] - 3s 19ms/step - loss: 0.6352 - accuracy: 0.7271\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=16__optimizer=adamw__class_weights=none__dropout=0.4 completed.\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirectio  (None, None, 64)         24832     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, None, 16)          1040      \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, None, 16)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_8   (None, 16)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 345,906\n",
      "Trainable params: 345,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=1e-05__hidden_unit=16__batch_size=32__optimizer=adamw__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "166/166 [==============================] - 22s 87ms/step - loss: 0.7549 - accuracy: 0.5380 - val_loss: 0.7239 - val_accuracy: 0.5473\n",
      "Epoch 2/3\n",
      "166/166 [==============================] - 13s 72ms/step - loss: 0.7547 - accuracy: 0.5804 - val_loss: 0.7238 - val_accuracy: 0.5473\n",
      "Epoch 3/3\n",
      "166/166 [==============================] - 13s 73ms/step - loss: 0.7545 - accuracy: 0.5826 - val_loss: 0.7237 - val_accuracy: 0.5464\n",
      "35/35 [==============================] - 2s 21ms/step - loss: 0.7237 - accuracy: 0.5616\n",
      "run=0__lr=1e-05__hidden_unit=16__batch_size=32__optimizer=adamw__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_9 (Embedding)     (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_9 (Bidirectio  (None, None, 64)         24832     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, None, 16)          1040      \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, None, 16)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_9   (None, 16)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 345,906\n",
      "Trainable params: 345,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=1e-05__hidden_unit=16__batch_size=32__optimizer=adamw__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "166/166 [==============================] - 22s 91ms/step - loss: 0.7240 - accuracy: 0.4893 - val_loss: 0.7239 - val_accuracy: 0.5179\n",
      "Epoch 2/3\n",
      "166/166 [==============================] - 13s 71ms/step - loss: 0.7238 - accuracy: 0.5452 - val_loss: 0.7238 - val_accuracy: 0.5500\n",
      "Epoch 3/3\n",
      "166/166 [==============================] - 13s 73ms/step - loss: 0.7237 - accuracy: 0.5672 - val_loss: 0.7237 - val_accuracy: 0.5473\n",
      "35/35 [==============================] - 2s 21ms/step - loss: 0.7236 - accuracy: 0.5554\n",
      "run=0__lr=1e-05__hidden_unit=16__batch_size=32__optimizer=adamw__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_10 (Embedding)    (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_10 (Bidirecti  (None, None, 64)         24832     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, None, 16)          1040      \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, None, 16)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_10  (None, 16)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 345,906\n",
      "Trainable params: 345,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=1e-05__hidden_unit=16__batch_size=32__optimizer=adamw__class_weights=balanced__dropout=0.4 starting...\n",
      "Epoch 1/3\n",
      "166/166 [==============================] - 22s 87ms/step - loss: 0.7551 - accuracy: 0.4944 - val_loss: 0.7239 - val_accuracy: 0.5089\n",
      "Epoch 2/3\n",
      "166/166 [==============================] - 12s 68ms/step - loss: 0.7548 - accuracy: 0.5346 - val_loss: 0.7238 - val_accuracy: 0.5348\n",
      "Epoch 3/3\n",
      "166/166 [==============================] - 13s 70ms/step - loss: 0.7546 - accuracy: 0.5525 - val_loss: 0.7237 - val_accuracy: 0.5330\n",
      "35/35 [==============================] - 2s 20ms/step - loss: 0.7237 - accuracy: 0.5482\n",
      "run=0__lr=1e-05__hidden_unit=16__batch_size=32__optimizer=adamw__class_weights=balanced__dropout=0.4 completed.\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_11 (Embedding)    (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_11 (Bidirecti  (None, None, 64)         24832     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, None, 16)          1040      \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, None, 16)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_11  (None, 16)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 345,906\n",
      "Trainable params: 345,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=1e-05__hidden_unit=16__batch_size=32__optimizer=adamw__class_weights=none__dropout=0.4 starting...\n",
      "Epoch 1/3\n",
      "166/166 [==============================] - 21s 86ms/step - loss: 0.7238 - accuracy: 0.5190 - val_loss: 0.7237 - val_accuracy: 0.5357\n",
      "Epoch 2/3\n",
      "166/166 [==============================] - 13s 69ms/step - loss: 0.7236 - accuracy: 0.5360 - val_loss: 0.7236 - val_accuracy: 0.5402\n",
      "Epoch 3/3\n",
      "166/166 [==============================] - 13s 69ms/step - loss: 0.7235 - accuracy: 0.5499 - val_loss: 0.7235 - val_accuracy: 0.5437\n",
      "35/35 [==============================] - 2s 20ms/step - loss: 0.7235 - accuracy: 0.5616\n",
      "run=0__lr=1e-05__hidden_unit=16__batch_size=32__optimizer=adamw__class_weights=none__dropout=0.4 completed.\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_12 (Embedding)    (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_12 (Bidirecti  (None, None, 64)         24832     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, None, 16)          1040      \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, None, 16)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_12  (None, 16)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 345,906\n",
      "Trainable params: 345,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=32__optimizer=adamw__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "166/166 [==============================] - 20s 86ms/step - loss: 0.7205 - accuracy: 0.5828 - val_loss: 0.6928 - val_accuracy: 0.5902\n",
      "Epoch 2/3\n",
      "166/166 [==============================] - 13s 70ms/step - loss: 0.6526 - accuracy: 0.7276 - val_loss: 0.6470 - val_accuracy: 0.7054\n",
      "Epoch 3/3\n",
      "166/166 [==============================] - 13s 72ms/step - loss: 0.6118 - accuracy: 0.8183 - val_loss: 0.6428 - val_accuracy: 0.7054\n",
      "35/35 [==============================] - 2s 21ms/step - loss: 0.6363 - accuracy: 0.7170\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=32__optimizer=adamw__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_13 (Embedding)    (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_13 (Bidirecti  (None, None, 64)         24832     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, None, 16)          1040      \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, None, 16)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_13  (None, 16)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 345,906\n",
      "Trainable params: 345,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=32__optimizer=adamw__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "166/166 [==============================] - 23s 93ms/step - loss: 0.7038 - accuracy: 0.5761 - val_loss: 0.6891 - val_accuracy: 0.5714\n",
      "Epoch 2/3\n",
      "166/166 [==============================] - 15s 83ms/step - loss: 0.6535 - accuracy: 0.6888 - val_loss: 0.6496 - val_accuracy: 0.6955\n",
      "Epoch 3/3\n",
      "166/166 [==============================] - 16s 88ms/step - loss: 0.6037 - accuracy: 0.8031 - val_loss: 0.6441 - val_accuracy: 0.7063\n",
      "35/35 [==============================] - 2s 24ms/step - loss: 0.6374 - accuracy: 0.7161\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=32__optimizer=adamw__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_14 (Embedding)    (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_14 (Bidirecti  (None, None, 64)         24832     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, None, 16)          1040      \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, None, 16)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_14  (None, 16)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 345,906\n",
      "Trainable params: 345,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=32__optimizer=adamw__class_weights=balanced__dropout=0.4 starting...\n",
      "Epoch 1/3\n",
      "166/166 [==============================] - 24s 99ms/step - loss: 0.7239 - accuracy: 0.5793 - val_loss: 0.6968 - val_accuracy: 0.5750\n",
      "Epoch 2/3\n",
      "166/166 [==============================] - 14s 77ms/step - loss: 0.6666 - accuracy: 0.6928 - val_loss: 0.6551 - val_accuracy: 0.6893\n",
      "Epoch 3/3\n",
      "166/166 [==============================] - 15s 85ms/step - loss: 0.6228 - accuracy: 0.8070 - val_loss: 0.6487 - val_accuracy: 0.7027\n",
      "35/35 [==============================] - 2s 21ms/step - loss: 0.6408 - accuracy: 0.7179\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=32__optimizer=adamw__class_weights=balanced__dropout=0.4 completed.\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_15 (Embedding)    (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_15 (Bidirecti  (None, None, 64)         24832     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, None, 16)          1040      \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, None, 16)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_15  (None, 16)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 345,906\n",
      "Trainable params: 345,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=32__optimizer=adamw__class_weights=none__dropout=0.4 starting...\n",
      "Epoch 1/3\n",
      "166/166 [==============================] - 24s 97ms/step - loss: 0.7082 - accuracy: 0.5569 - val_loss: 0.6914 - val_accuracy: 0.5500\n",
      "Epoch 2/3\n",
      "166/166 [==============================] - 14s 76ms/step - loss: 0.6768 - accuracy: 0.6359 - val_loss: 0.6683 - val_accuracy: 0.6321\n",
      "Epoch 3/3\n",
      "166/166 [==============================] - 13s 72ms/step - loss: 0.6412 - accuracy: 0.7526 - val_loss: 0.6551 - val_accuracy: 0.6946\n",
      "35/35 [==============================] - 2s 21ms/step - loss: 0.6479 - accuracy: 0.7054\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=32__optimizer=adamw__class_weights=none__dropout=0.4 completed.\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_16 (Embedding)    (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_16 (Bidirecti  (None, None, 64)         24832     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, None, 64)          4160      \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, None, 64)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_16  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 349,122\n",
      "Trainable params: 349,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=1e-05__hidden_unit=64__batch_size=16__optimizer=adamw__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "333/333 [==============================] - 34s 80ms/step - loss: 0.7548 - accuracy: 0.5702 - val_loss: 0.7237 - val_accuracy: 0.5440\n",
      "Epoch 2/3\n",
      "333/333 [==============================] - 24s 69ms/step - loss: 0.7540 - accuracy: 0.5792 - val_loss: 0.7233 - val_accuracy: 0.5431\n",
      "Epoch 3/3\n",
      "333/333 [==============================] - 25s 73ms/step - loss: 0.7536 - accuracy: 0.5790 - val_loss: 0.7232 - val_accuracy: 0.5431\n",
      "71/71 [==============================] - 3s 19ms/step - loss: 0.7231 - accuracy: 0.5572\n",
      "run=0__lr=1e-05__hidden_unit=64__batch_size=16__optimizer=adamw__class_weights=balanced__dropout=0.1 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sersery/anaconda3/envs/tf-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_17 (Embedding)    (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_17 (Bidirecti  (None, None, 64)         24832     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, None, 64)          4160      \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, None, 64)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_17  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 349,122\n",
      "Trainable params: 349,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=1e-05__hidden_unit=64__batch_size=16__optimizer=adamw__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "333/333 [==============================] - 32s 72ms/step - loss: 0.7238 - accuracy: 0.5636 - val_loss: 0.7236 - val_accuracy: 0.5599\n",
      "Epoch 2/3\n",
      "333/333 [==============================] - 25s 69ms/step - loss: 0.7234 - accuracy: 0.5766 - val_loss: 0.7233 - val_accuracy: 0.5396\n",
      "Epoch 3/3\n",
      "333/333 [==============================] - 25s 71ms/step - loss: 0.7231 - accuracy: 0.5816 - val_loss: 0.7232 - val_accuracy: 0.5449\n",
      "71/71 [==============================] - 3s 20ms/step - loss: 0.7232 - accuracy: 0.5590\n",
      "run=0__lr=1e-05__hidden_unit=64__batch_size=16__optimizer=adamw__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_18 (Embedding)    (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_18 (Bidirecti  (None, None, 64)         24832     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, None, 64)          4160      \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, None, 64)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_18  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 349,122\n",
      "Trainable params: 349,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=1e-05__hidden_unit=64__batch_size=16__optimizer=adamw__class_weights=balanced__dropout=0.4 starting...\n",
      "Epoch 1/3\n",
      "333/333 [==============================] - 36s 84ms/step - loss: 0.7547 - accuracy: 0.5599 - val_loss: 0.7236 - val_accuracy: 0.5431\n",
      "Epoch 2/3\n",
      "333/333 [==============================] - 28s 79ms/step - loss: 0.7539 - accuracy: 0.5785 - val_loss: 0.7233 - val_accuracy: 0.5431\n",
      "Epoch 3/3\n",
      "333/333 [==============================] - 31s 89ms/step - loss: 0.7535 - accuracy: 0.5788 - val_loss: 0.7232 - val_accuracy: 0.5431\n",
      "71/71 [==============================] - 4s 22ms/step - loss: 0.7231 - accuracy: 0.5572\n",
      "run=0__lr=1e-05__hidden_unit=64__batch_size=16__optimizer=adamw__class_weights=balanced__dropout=0.4 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sersery/anaconda3/envs/tf-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_19 (Embedding)    (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_19 (Bidirecti  (None, None, 64)         24832     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, None, 64)          4160      \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, None, 64)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_19  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 349,122\n",
      "Trainable params: 349,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=1e-05__hidden_unit=64__batch_size=16__optimizer=adamw__class_weights=none__dropout=0.4 starting...\n",
      "Epoch 1/3\n",
      "333/333 [==============================] - 39s 90ms/step - loss: 0.7240 - accuracy: 0.4992 - val_loss: 0.7238 - val_accuracy: 0.5511\n",
      "Epoch 2/3\n",
      "333/333 [==============================] - 31s 87ms/step - loss: 0.7236 - accuracy: 0.5424 - val_loss: 0.7235 - val_accuracy: 0.5475\n",
      "Epoch 3/3\n",
      "333/333 [==============================] - 30s 84ms/step - loss: 0.7234 - accuracy: 0.5651 - val_loss: 0.7234 - val_accuracy: 0.5581\n",
      "71/71 [==============================] - 3s 19ms/step - loss: 0.7234 - accuracy: 0.5484\n",
      "run=0__lr=1e-05__hidden_unit=64__batch_size=16__optimizer=adamw__class_weights=none__dropout=0.4 completed.\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_20 (Embedding)    (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_20 (Bidirecti  (None, None, 64)         24832     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, None, 64)          4160      \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, None, 64)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_20  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 349,122\n",
      "Trainable params: 349,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=16__optimizer=adamw__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "333/333 [==============================] - 32s 73ms/step - loss: 0.7010 - accuracy: 0.6237 - val_loss: 0.6520 - val_accuracy: 0.6857\n",
      "Epoch 2/3\n",
      "333/333 [==============================] - 22s 64ms/step - loss: 0.6218 - accuracy: 0.7900 - val_loss: 0.6404 - val_accuracy: 0.7095\n",
      "Epoch 3/3\n",
      "333/333 [==============================] - 25s 69ms/step - loss: 0.5945 - accuracy: 0.8512 - val_loss: 0.6396 - val_accuracy: 0.7201\n",
      "71/71 [==============================] - 3s 19ms/step - loss: 0.6350 - accuracy: 0.7254\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=16__optimizer=adamw__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_21 (Embedding)    (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_21 (Bidirecti  (None, None, 64)         24832     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, None, 64)          4160      \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, None, 64)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_21  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 349,122\n",
      "Trainable params: 349,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=16__optimizer=adamw__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "333/333 [==============================] - 36s 86ms/step - loss: 0.6889 - accuracy: 0.6044 - val_loss: 0.6499 - val_accuracy: 0.6857\n",
      "Epoch 2/3\n",
      "333/333 [==============================] - 24s 69ms/step - loss: 0.6096 - accuracy: 0.7798 - val_loss: 0.6373 - val_accuracy: 0.7121\n",
      "Epoch 3/3\n",
      "333/333 [==============================] - 24s 68ms/step - loss: 0.5809 - accuracy: 0.8423 - val_loss: 0.6363 - val_accuracy: 0.7245\n",
      "71/71 [==============================] - 3s 19ms/step - loss: 0.6337 - accuracy: 0.7148\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=16__optimizer=adamw__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_22 (Embedding)    (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_22 (Bidirecti  (None, None, 64)         24832     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, None, 64)          4160      \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, None, 64)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_22  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 349,122\n",
      "Trainable params: 349,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=16__optimizer=adamw__class_weights=balanced__dropout=0.4 starting...\n",
      "Epoch 1/3\n",
      "333/333 [==============================] - 32s 74ms/step - loss: 0.7072 - accuracy: 0.6060 - val_loss: 0.6589 - val_accuracy: 0.6629\n",
      "Epoch 2/3\n",
      "333/333 [==============================] - 26s 74ms/step - loss: 0.6266 - accuracy: 0.7797 - val_loss: 0.6433 - val_accuracy: 0.7033\n",
      "Epoch 3/3\n",
      "333/333 [==============================] - 23s 66ms/step - loss: 0.5982 - accuracy: 0.8444 - val_loss: 0.6414 - val_accuracy: 0.7060\n",
      "71/71 [==============================] - 2s 17ms/step - loss: 0.6312 - accuracy: 0.7315\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=16__optimizer=adamw__class_weights=balanced__dropout=0.4 completed.\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_23 (Embedding)    (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_23 (Bidirecti  (None, None, 64)         24832     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, None, 64)          4160      \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, None, 64)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_23  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 349,122\n",
      "Trainable params: 349,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=16__optimizer=adamw__class_weights=none__dropout=0.4 starting...\n",
      "Epoch 1/3\n",
      "333/333 [==============================] - 33s 76ms/step - loss: 0.6945 - accuracy: 0.5892 - val_loss: 0.6653 - val_accuracy: 0.6444\n",
      "Epoch 2/3\n",
      "333/333 [==============================] - 25s 71ms/step - loss: 0.6198 - accuracy: 0.7590 - val_loss: 0.6385 - val_accuracy: 0.7148\n",
      "Epoch 3/3\n",
      "333/333 [==============================] - 26s 74ms/step - loss: 0.5851 - accuracy: 0.8352 - val_loss: 0.6380 - val_accuracy: 0.7174\n",
      "71/71 [==============================] - 3s 18ms/step - loss: 0.6334 - accuracy: 0.7262\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=16__optimizer=adamw__class_weights=none__dropout=0.4 completed.\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_24 (Embedding)    (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_24 (Bidirecti  (None, None, 64)         24832     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, None, 64)          4160      \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, None, 64)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_24  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 349,122\n",
      "Trainable params: 349,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=1e-05__hidden_unit=64__batch_size=32__optimizer=adamw__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "166/166 [==============================] - 26s 107ms/step - loss: 0.7550 - accuracy: 0.5271 - val_loss: 0.7239 - val_accuracy: 0.5455\n",
      "Epoch 2/3\n",
      "166/166 [==============================] - 15s 84ms/step - loss: 0.7546 - accuracy: 0.5781 - val_loss: 0.7237 - val_accuracy: 0.5473\n",
      "Epoch 3/3\n",
      "166/166 [==============================] - 15s 80ms/step - loss: 0.7544 - accuracy: 0.5821 - val_loss: 0.7236 - val_accuracy: 0.5446\n",
      "35/35 [==============================] - 2s 25ms/step - loss: 0.7236 - accuracy: 0.5580\n",
      "run=0__lr=1e-05__hidden_unit=64__batch_size=32__optimizer=adamw__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_25 (Embedding)    (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_25 (Bidirecti  (None, None, 64)         24832     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, None, 64)          4160      \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, None, 64)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_25  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 349,122\n",
      "Trainable params: 349,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=1e-05__hidden_unit=64__batch_size=32__optimizer=adamw__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "166/166 [==============================] - 27s 114ms/step - loss: 0.7238 - accuracy: 0.5693 - val_loss: 0.7237 - val_accuracy: 0.5402\n",
      "Epoch 2/3\n",
      "166/166 [==============================] - 15s 82ms/step - loss: 0.7235 - accuracy: 0.5781 - val_loss: 0.7235 - val_accuracy: 0.5429\n",
      "Epoch 3/3\n",
      "166/166 [==============================] - 15s 79ms/step - loss: 0.7233 - accuracy: 0.5783 - val_loss: 0.7234 - val_accuracy: 0.5437\n",
      "35/35 [==============================] - 2s 22ms/step - loss: 0.7234 - accuracy: 0.5607\n",
      "run=0__lr=1e-05__hidden_unit=64__batch_size=32__optimizer=adamw__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_26 (Embedding)    (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_26 (Bidirecti  (None, None, 64)         24832     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, None, 64)          4160      \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, None, 64)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_26  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 349,122\n",
      "Trainable params: 349,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=1e-05__hidden_unit=64__batch_size=32__optimizer=adamw__class_weights=balanced__dropout=0.4 starting...\n",
      "Epoch 1/3\n",
      "166/166 [==============================] - 26s 108ms/step - loss: 0.7553 - accuracy: 0.4671 - val_loss: 0.7241 - val_accuracy: 0.4786\n",
      "Epoch 2/3\n",
      "166/166 [==============================] - 17s 97ms/step - loss: 0.7549 - accuracy: 0.5064 - val_loss: 0.7239 - val_accuracy: 0.5161\n",
      "Epoch 3/3\n",
      "166/166 [==============================] - 19s 103ms/step - loss: 0.7547 - accuracy: 0.5378 - val_loss: 0.7239 - val_accuracy: 0.5241\n",
      "35/35 [==============================] - 4s 30ms/step - loss: 0.7238 - accuracy: 0.5661\n",
      "run=0__lr=1e-05__hidden_unit=64__batch_size=32__optimizer=adamw__class_weights=balanced__dropout=0.4 completed.\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_27 (Embedding)    (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_27 (Bidirecti  (None, None, 64)         24832     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, None, 64)          4160      \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, None, 64)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_27  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 349,122\n",
      "Trainable params: 349,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=1e-05__hidden_unit=64__batch_size=32__optimizer=adamw__class_weights=none__dropout=0.4 starting...\n",
      "Epoch 1/3\n",
      "166/166 [==============================] - 32s 133ms/step - loss: 0.7240 - accuracy: 0.4938 - val_loss: 0.7239 - val_accuracy: 0.4946\n",
      "Epoch 2/3\n",
      "166/166 [==============================] - 18s 99ms/step - loss: 0.7239 - accuracy: 0.5250 - val_loss: 0.7238 - val_accuracy: 0.5357\n",
      "Epoch 3/3\n",
      "166/166 [==============================] - 15s 83ms/step - loss: 0.7237 - accuracy: 0.5510 - val_loss: 0.7237 - val_accuracy: 0.5446\n",
      "35/35 [==============================] - 2s 22ms/step - loss: 0.7237 - accuracy: 0.5527\n",
      "run=0__lr=1e-05__hidden_unit=64__batch_size=32__optimizer=adamw__class_weights=none__dropout=0.4 completed.\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_28 (Embedding)    (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_28 (Bidirecti  (None, None, 64)         24832     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, None, 64)          4160      \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, None, 64)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_28  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_57 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 349,122\n",
      "Trainable params: 349,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=32__optimizer=adamw__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "166/166 [==============================] - 29s 128ms/step - loss: 0.7186 - accuracy: 0.5772 - val_loss: 0.6918 - val_accuracy: 0.5902\n",
      "Epoch 2/3\n",
      "166/166 [==============================] - 23s 122ms/step - loss: 0.6463 - accuracy: 0.7348 - val_loss: 0.6466 - val_accuracy: 0.7018\n",
      "Epoch 3/3\n",
      "166/166 [==============================] - 17s 94ms/step - loss: 0.6075 - accuracy: 0.8240 - val_loss: 0.6438 - val_accuracy: 0.7098\n",
      "35/35 [==============================] - 3s 25ms/step - loss: 0.6355 - accuracy: 0.7223\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=32__optimizer=adamw__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_29 (Embedding)    (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_29 (Bidirecti  (None, None, 64)         24832     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, None, 64)          4160      \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, None, 64)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_29  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 349,122\n",
      "Trainable params: 349,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=32__optimizer=adamw__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "166/166 [==============================] - 27s 109ms/step - loss: 0.7005 - accuracy: 0.5796 - val_loss: 0.6881 - val_accuracy: 0.5857\n",
      "Epoch 2/3\n",
      "166/166 [==============================] - 17s 90ms/step - loss: 0.6391 - accuracy: 0.7238 - val_loss: 0.6432 - val_accuracy: 0.7063\n",
      "Epoch 3/3\n",
      "166/166 [==============================] - 16s 86ms/step - loss: 0.5922 - accuracy: 0.8187 - val_loss: 0.6411 - val_accuracy: 0.7116\n",
      "35/35 [==============================] - 2s 24ms/step - loss: 0.6325 - accuracy: 0.7277\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=32__optimizer=adamw__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_30 (Embedding)    (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_30 (Bidirecti  (None, None, 64)         24832     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, None, 64)          4160      \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, None, 64)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_30  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 349,122\n",
      "Trainable params: 349,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=32__optimizer=adamw__class_weights=balanced__dropout=0.4 starting...\n",
      "Epoch 1/3\n",
      "166/166 [==============================] - 26s 112ms/step - loss: 0.7198 - accuracy: 0.5836 - val_loss: 0.6926 - val_accuracy: 0.5875\n",
      "Epoch 2/3\n",
      "166/166 [==============================] - 18s 98ms/step - loss: 0.6494 - accuracy: 0.7310 - val_loss: 0.6458 - val_accuracy: 0.7063\n",
      "Epoch 3/3\n",
      "166/166 [==============================] - 16s 86ms/step - loss: 0.6090 - accuracy: 0.8232 - val_loss: 0.6420 - val_accuracy: 0.7170\n",
      "35/35 [==============================] - 2s 22ms/step - loss: 0.6390 - accuracy: 0.7089\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=32__optimizer=adamw__class_weights=balanced__dropout=0.4 completed.\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_31 (Embedding)    (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_31 (Bidirecti  (None, None, 64)         24832     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, None, 64)          4160      \n",
      "                                                                 \n",
      " dropout_62 (Dropout)        (None, None, 64)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d_31  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_63 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 349,122\n",
      "Trainable params: 349,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=32__optimizer=adamw__class_weights=none__dropout=0.4 starting...\n",
      "Epoch 1/3\n",
      "166/166 [==============================] - 26s 104ms/step - loss: 0.7029 - accuracy: 0.5730 - val_loss: 0.6915 - val_accuracy: 0.5446\n",
      "Epoch 2/3\n",
      "166/166 [==============================] - 15s 85ms/step - loss: 0.6661 - accuracy: 0.6459 - val_loss: 0.6539 - val_accuracy: 0.6875\n",
      "Epoch 3/3\n",
      "166/166 [==============================] - 14s 78ms/step - loss: 0.6073 - accuracy: 0.7993 - val_loss: 0.6445 - val_accuracy: 0.6964\n",
      "35/35 [==============================] - 2s 21ms/step - loss: 0.6347 - accuracy: 0.7250\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=32__optimizer=adamw__class_weights=none__dropout=0.4 completed.\n"
     ]
    }
   ],
   "source": [
    "session_num = 1\n",
    "hyperparameters = {\"learning_rate\": hp.HParam(\"learning_rate\", hp.RealInterval(1e-5, 1e-3)),\n",
    "                   \"hidden_unit\": hp.HParam(\"hidden_unit\", hp.Discrete([16, 64])),\n",
    "                   \"batch_size\": hp.HParam(\"batch_size\", hp.Discrete([16, 32])),\n",
    "                   \"optimizer\": hp.HParam(\"optimizer\", hp.Discrete([\"adamw\"])),\n",
    "                   \"class_weights\": hp.HParam(\"class_weights\", hp.Discrete([\"none\", \"balanced\"])),\n",
    "                   \"dropout\": hp.HParam(\"dropout\", hp.Discrete([0.1, 0.4]))}\n",
    "# look for the best hyperparameters\n",
    "for optimizer in hyperparameters[\"optimizer\"].domain.values:\n",
    "    for hidden_unit in hyperparameters[\"hidden_unit\"].domain.values:\n",
    "        for batch_size in hyperparameters[\"batch_size\"].domain.values:\n",
    "            for learning_rate in (hyperparameters[\"learning_rate\"].domain.min_value,\n",
    "                                  hyperparameters[\"learning_rate\"].domain.max_value):\n",
    "                for dropout in hyperparameters[\"dropout\"].domain.values:\n",
    "                    for class_weights in hyperparameters[\"class_weights\"].domain.values:\n",
    "                        print(f\"********************Session {session_num} started**********************\")\n",
    "                        hparams = {\n",
    "                            hyperparameters[\"optimizer\"]: optimizer,\n",
    "                            hyperparameters[\"hidden_unit\"]: hidden_unit,\n",
    "                            hyperparameters[\"batch_size\"]: batch_size,\n",
    "                            hyperparameters[\"learning_rate\"]: learning_rate,\n",
    "                            hyperparameters[\"class_weights\"]: class_weights,\n",
    "                            hyperparameters[\"dropout\"]: dropout,\n",
    "                        }\n",
    "                        model = base_model.BaseModel(\n",
    "                            vocabulary_size=data_pipeline.vocabulary_size,\n",
    "                            embedding_dim=64,\n",
    "                            hidden_dim=128,\n",
    "                            lstm_dim=64,\n",
    "                            n_labels=2,\n",
    "                            epochs=10,\n",
    "                            batch_pipeline=BatchPipeline(dataset, batch_size),\n",
    "                            hparam_manager=utils.HyperparameterManager(hparams),\n",
    "                            embeddings_initializer=tf.keras.initializers.LecunUniform())\n",
    "                            # embeddings_initializer=data_pipeline.build_embeddings_initializer())\n",
    "\n",
    "                        with tf.summary.create_file_writer(f'{log_directory}{model.run_name}').as_default():\n",
    "                            hp.hparams(hparams)\n",
    "                            accuracy, precision, recall, f1, predictions = model.fit_and_evaluate(\n",
    "                                class_weights=balanced_class_weights,\n",
    "                                log_directory=log_directory)\n",
    "                            tf.summary.scalar(\"accuracy\", accuracy, step=1)\n",
    "                            tf.summary.scalar(\"precision\", precision, step=1)\n",
    "                            tf.summary.scalar(\"recall\", recall, step=1)\n",
    "                            tf.summary.scalar(\"f1\", f1, step=1)\n",
    "                        session_num+=1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensorboard --logdir logs/hyperparameter_tuning_BaseModel --port 5000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}