{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from KAGGLE_NLP_with_disaster_tweets.model import base_model, utils, constants\n",
    "from KAGGLE_NLP_with_disaster_tweets.data_preparation.utils import DataPipeline, BatchPipeline\n",
    "\n",
    "from tensorboard import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train_file_name = 'train.csv'\n",
    "test_file_name = 'test.csv'\n",
    "sample_submission_file_name = 'sample_submission.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-26 20:36:19.027432: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-01-26 20:36:19.027524: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: sersery-asusVivo\n",
      "2022-01-26 20:36:19.027545: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: sersery-asusVivo\n",
      "2022-01-26 20:36:19.027763: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 495.29.5\n",
      "2022-01-26 20:36:19.027829: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 495.29.5\n",
      "2022-01-26 20:36:19.027847: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 495.29.5\n",
      "2022-01-26 20:36:19.028348: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the file: ../data/train.csv\n",
      "-----------------------------------------------------------------------------------------\n",
      "Dataset \n",
      "Size: 7613\n",
      "Dataset examples:\n",
      "Input: [ 582 1716    1    1    1  662   99  145   87    1  662    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "Target: [0. 1.]\n",
      "Input: [ 209  813  539    8 3344    2  209    5   13 2051    1  743    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "Target: [1. 0.]\n",
      "Input: [   1  104  270    3  270 1154   16   24  419 4823   29    5   40  472\n",
      "    4 3684    4  804    9   52    4 1956 1727   19    9  764    3    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "Target: [1. 0.]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Getting the file: ../data/test.csv\n",
      "Getting the file: ../data/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "data_pipeline = DataPipeline(train_file_name, test_file_name, sample_submission_file_name)\n",
    "dataset, submission_test_dataset = data_pipeline.prepare_datasets()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "balanced_class_weights = utils.get_balanced_class_weights(data_pipeline.dataframe)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "log_directory = \"../logs/hyperparameter_tuning/\"\n",
    "utils.start_logging(log_directory, constants.hyperparameters, constants.metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 64)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 4s 7ms/step - loss: 0.5805 - accuracy: 0.6801 - val_loss: 0.4415 - val_accuracy: 0.8298\n",
      "Epoch 2/3\n",
      " 36/380 [=>............................] - ETA: 1s - loss: 0.4259 - accuracy: 0.8299"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-26 20:36:29.807727: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 76815360 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380/380 [==============================] - 1s 4ms/step - loss: 0.3884 - accuracy: 0.8424 - val_loss: 0.3368 - val_accuracy: 0.8697\n",
      "Epoch 3/3\n",
      " 32/380 [=>............................] - ETA: 1s - loss: 0.3317 - accuracy: 0.8613"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-26 20:36:31.216436: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 76815360 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380/380 [==============================] - 1s 4ms/step - loss: 0.3091 - accuracy: 0.8762 - val_loss: 0.2899 - val_accuracy: 0.8923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-26 20:36:32.639833: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 76815360 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 1s 1ms/step - loss: 0.2942 - accuracy: 0.8843\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_1   (None, 64)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=16__optimizer=adam__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 4s 7ms/step - loss: 0.5790 - accuracy: 0.7046 - val_loss: 0.4148 - val_accuracy: 0.8497\n",
      "Epoch 2/3\n",
      " 31/380 [=>............................] - ETA: 1s - loss: 0.4414 - accuracy: 0.8165"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-26 20:36:38.569534: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 76815360 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380/380 [==============================] - 1s 4ms/step - loss: 0.3870 - accuracy: 0.8385 - val_loss: 0.3317 - val_accuracy: 0.8710\n",
      "Epoch 3/3\n",
      " 32/380 [=>............................] - ETA: 1s - loss: 0.3567 - accuracy: 0.8359"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-26 20:36:40.016552: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 76815360 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380/380 [==============================] - 1s 4ms/step - loss: 0.3135 - accuracy: 0.8712 - val_loss: 0.2917 - val_accuracy: 0.8963\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 0.2901 - accuracy: 0.9003\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=16__optimizer=adam__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_2   (None, 64)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 4s 7ms/step - loss: 0.5836 - accuracy: 0.6729 - val_loss: 0.3828 - val_accuracy: 0.8511\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 0.3854 - accuracy: 0.8337 - val_loss: 0.3042 - val_accuracy: 0.8830\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 0.3136 - accuracy: 0.8729 - val_loss: 0.2735 - val_accuracy: 0.9029\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 0.3052 - accuracy: 0.8843\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_3   (None, 64)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=16__optimizer=adam__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 4s 6ms/step - loss: 0.5731 - accuracy: 0.7054 - val_loss: 0.4413 - val_accuracy: 0.8178\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.3763 - accuracy: 0.8433 - val_loss: 0.3676 - val_accuracy: 0.8564\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.3004 - accuracy: 0.8834 - val_loss: 0.3339 - val_accuracy: 0.8763\n",
      "47/47 [==============================] - 1s 992us/step - loss: 0.3184 - accuracy: 0.8697\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=16__optimizer=adam__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_4   (None, 64)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 4s 6ms/step - loss: 0.5734 - accuracy: 0.6845 - val_loss: 0.4106 - val_accuracy: 0.8351\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.3746 - accuracy: 0.8388 - val_loss: 0.3348 - val_accuracy: 0.8750\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.3028 - accuracy: 0.8755 - val_loss: 0.2985 - val_accuracy: 0.8936\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 0.2607 - accuracy: 0.9096\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_5   (None, 64)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=16__optimizer=adam__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 4s 6ms/step - loss: 0.5687 - accuracy: 0.7217 - val_loss: 0.4117 - val_accuracy: 0.8271\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.3793 - accuracy: 0.8413 - val_loss: 0.3419 - val_accuracy: 0.8710\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.3077 - accuracy: 0.8762 - val_loss: 0.2961 - val_accuracy: 0.8830\n",
      "47/47 [==============================] - 1s 945us/step - loss: 0.2501 - accuracy: 0.8989\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=16__optimizer=adam__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_6   (None, 64)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 4s 6ms/step - loss: 0.5665 - accuracy: 0.7380 - val_loss: 0.4892 - val_accuracy: 0.7992\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.5529 - accuracy: 0.8467 - val_loss: 0.8721 - val_accuracy: 0.8165\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.8892 - accuracy: 0.8584 - val_loss: 3.3471 - val_accuracy: 0.8059\n",
      "47/47 [==============================] - 1s 930us/step - loss: 4.2152 - accuracy: 0.7912\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_7   (None, 64)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=16__optimizer=adam__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 4s 6ms/step - loss: 0.5614 - accuracy: 0.7359 - val_loss: 0.4711 - val_accuracy: 0.8019\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.6604 - accuracy: 0.8189 - val_loss: 1.1598 - val_accuracy: 0.7434\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.5441 - accuracy: 0.8530 - val_loss: 1.0070 - val_accuracy: 0.7859\n",
      "47/47 [==============================] - 1s 983us/step - loss: 0.9255 - accuracy: 0.7846\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=16__optimizer=adam__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_8   (None, 64)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 4s 6ms/step - loss: 0.5618 - accuracy: 0.7426 - val_loss: 0.4109 - val_accuracy: 0.8338\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.7869 - accuracy: 0.8153 - val_loss: 0.9333 - val_accuracy: 0.8258\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.6724 - accuracy: 0.8429 - val_loss: 1.2977 - val_accuracy: 0.8191\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 1.2259 - accuracy: 0.8152\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_9 (Embedding)     (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_9   (None, 64)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=16__optimizer=adam__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 4s 6ms/step - loss: 0.5616 - accuracy: 0.7418 - val_loss: 0.4981 - val_accuracy: 0.8444\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.7134 - accuracy: 0.8176 - val_loss: 0.5100 - val_accuracy: 0.8338\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.5751 - accuracy: 0.8502 - val_loss: 0.6540 - val_accuracy: 0.8604\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 0.8092 - accuracy: 0.8364\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=16__optimizer=adam__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_10 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_10  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 4s 6ms/step - loss: 0.5740 - accuracy: 0.7281 - val_loss: 0.3869 - val_accuracy: 0.8298\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.9191 - accuracy: 0.8102 - val_loss: 0.5480 - val_accuracy: 0.7979\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.5286 - accuracy: 0.8564 - val_loss: 0.6740 - val_accuracy: 0.8338\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 0.7976 - accuracy: 0.8564\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_11 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_11  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=16__optimizer=adam__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 4s 6ms/step - loss: 0.5768 - accuracy: 0.7449 - val_loss: 0.4740 - val_accuracy: 0.8138\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.6170 - accuracy: 0.8224 - val_loss: 1.6014 - val_accuracy: 0.8045\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.5704 - accuracy: 0.8627 - val_loss: 1.3945 - val_accuracy: 0.8271\n",
      "47/47 [==============================] - 1s 913us/step - loss: 1.6153 - accuracy: 0.8152\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=16__optimizer=adam__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_12 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_12  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 3s 9ms/step - loss: 0.6611 - accuracy: 0.6089 - val_loss: 0.5441 - val_accuracy: 0.7391\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4479 - accuracy: 0.7988 - val_loss: 0.4065 - val_accuracy: 0.8274\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3556 - accuracy: 0.8467 - val_loss: 0.3570 - val_accuracy: 0.8560\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.2975 - accuracy: 0.8832\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_13 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_13  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=32__optimizer=adam__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 3s 9ms/step - loss: 0.6203 - accuracy: 0.6737 - val_loss: 0.4764 - val_accuracy: 0.8288\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4248 - accuracy: 0.8294 - val_loss: 0.3310 - val_accuracy: 0.8859\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3325 - accuracy: 0.8664 - val_loss: 0.2819 - val_accuracy: 0.8995\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.3108 - accuracy: 0.8845\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=32__optimizer=adam__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_14 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_14  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 3s 9ms/step - loss: 0.6354 - accuracy: 0.6227 - val_loss: 0.4875 - val_accuracy: 0.7799\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4205 - accuracy: 0.8138 - val_loss: 0.3580 - val_accuracy: 0.8601\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3349 - accuracy: 0.8605 - val_loss: 0.3141 - val_accuracy: 0.8859\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.3099 - accuracy: 0.8845\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_15 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_15  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=32__optimizer=adam__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 3s 9ms/step - loss: 0.6268 - accuracy: 0.6780 - val_loss: 0.5073 - val_accuracy: 0.8098\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4265 - accuracy: 0.8280 - val_loss: 0.3812 - val_accuracy: 0.8478\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3432 - accuracy: 0.8622 - val_loss: 0.3321 - val_accuracy: 0.8668\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.3044 - accuracy: 0.8777\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=32__optimizer=adam__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_16 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_16  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 3s 9ms/step - loss: 0.6299 - accuracy: 0.6171 - val_loss: 0.5538 - val_accuracy: 0.7418\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4364 - accuracy: 0.8123 - val_loss: 0.4082 - val_accuracy: 0.8288\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3419 - accuracy: 0.8579 - val_loss: 0.3494 - val_accuracy: 0.8641\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.3304 - accuracy: 0.8668\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_17 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_17  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=32__optimizer=adam__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 3s 9ms/step - loss: 0.6136 - accuracy: 0.6862 - val_loss: 0.4809 - val_accuracy: 0.8098\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4123 - accuracy: 0.8296 - val_loss: 0.3706 - val_accuracy: 0.8410\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3300 - accuracy: 0.8678 - val_loss: 0.3259 - val_accuracy: 0.8709\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.2971 - accuracy: 0.8804\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=32__optimizer=adam__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_18 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_18  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 3s 9ms/step - loss: 0.5179 - accuracy: 0.7543 - val_loss: 0.3686 - val_accuracy: 0.8492\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4601 - accuracy: 0.8444 - val_loss: 0.6086 - val_accuracy: 0.7989\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4401 - accuracy: 0.8747 - val_loss: 1.0934 - val_accuracy: 0.7432\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 1.1284 - accuracy: 0.7391\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_19 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_19  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=32__optimizer=adam__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 3s 10ms/step - loss: 0.5381 - accuracy: 0.7523 - val_loss: 0.4183 - val_accuracy: 0.8274\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4873 - accuracy: 0.8298 - val_loss: 0.6437 - val_accuracy: 0.7935\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.5993 - accuracy: 0.8566 - val_loss: 0.5767 - val_accuracy: 0.7473\n",
      "23/23 [==============================] - 1s 988us/step - loss: 0.6541 - accuracy: 0.7568\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=32__optimizer=adam__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_20 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_20  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 3s 9ms/step - loss: 0.5113 - accuracy: 0.7577 - val_loss: 0.3856 - val_accuracy: 0.8465\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3901 - accuracy: 0.8635 - val_loss: 0.4700 - val_accuracy: 0.8084\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.5344 - accuracy: 0.8635 - val_loss: 0.9968 - val_accuracy: 0.8220\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.8404 - accuracy: 0.8111\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_21 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_21  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=32__optimizer=adam__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 3s 9ms/step - loss: 0.5305 - accuracy: 0.7563 - val_loss: 0.4509 - val_accuracy: 0.8152\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4494 - accuracy: 0.8357 - val_loss: 0.5589 - val_accuracy: 0.8234\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.5030 - accuracy: 0.8597 - val_loss: 0.9530 - val_accuracy: 0.8030\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.9671 - accuracy: 0.7840\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=32__optimizer=adam__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_22 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_22  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 11ms/step - loss: 0.5152 - accuracy: 0.7531 - val_loss: 0.3526 - val_accuracy: 0.8492\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4385 - accuracy: 0.8464 - val_loss: 0.4672 - val_accuracy: 0.8207\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4383 - accuracy: 0.8813 - val_loss: 1.4205 - val_accuracy: 0.7500\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 1.5828 - accuracy: 0.7160\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_23 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_23  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=32__optimizer=adam__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 12ms/step - loss: 0.5375 - accuracy: 0.7500 - val_loss: 0.3983 - val_accuracy: 0.8234\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4484 - accuracy: 0.8436 - val_loss: 0.7230 - val_accuracy: 0.7486\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4375 - accuracy: 0.8748 - val_loss: 0.9371 - val_accuracy: 0.7772\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.7400 - accuracy: 0.7948\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=32__optimizer=adam__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_24 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_24  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 19ms/step - loss: 0.6762 - accuracy: 0.5758 - val_loss: 0.6288 - val_accuracy: 0.5781\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 0.5481 - accuracy: 0.7178 - val_loss: 0.4756 - val_accuracy: 0.8054\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 0.4201 - accuracy: 0.8230 - val_loss: 0.3772 - val_accuracy: 0.8480\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.3514 - accuracy: 0.8864\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_25 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_25  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=64__optimizer=adam__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 18ms/step - loss: 0.6752 - accuracy: 0.6919 - val_loss: 0.6289 - val_accuracy: 0.8125\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.5584 - accuracy: 0.8090 - val_loss: 0.4705 - val_accuracy: 0.8381\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.4250 - accuracy: 0.8438 - val_loss: 0.3866 - val_accuracy: 0.8466\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.3966 - accuracy: 0.8423\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=64__optimizer=adam__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_26 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_26  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 20ms/step - loss: 0.6962 - accuracy: 0.5918 - val_loss: 0.6320 - val_accuracy: 0.6705\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.5530 - accuracy: 0.7359 - val_loss: 0.4635 - val_accuracy: 0.8054\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 0.4103 - accuracy: 0.8234 - val_loss: 0.3923 - val_accuracy: 0.8310\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.3813 - accuracy: 0.8338\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_27 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_27  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=64__optimizer=adam__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 22ms/step - loss: 0.6615 - accuracy: 0.6127 - val_loss: 0.5940 - val_accuracy: 0.7500\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.5106 - accuracy: 0.8008 - val_loss: 0.4379 - val_accuracy: 0.8224\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 0.3928 - accuracy: 0.8467 - val_loss: 0.3749 - val_accuracy: 0.8537\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.3630 - accuracy: 0.8565\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=64__optimizer=adam__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_28 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_28  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 21ms/step - loss: 0.6750 - accuracy: 0.5765 - val_loss: 0.6135 - val_accuracy: 0.6264\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.5400 - accuracy: 0.7288 - val_loss: 0.4619 - val_accuracy: 0.8139\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.4123 - accuracy: 0.8370 - val_loss: 0.3646 - val_accuracy: 0.8423\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.3579 - accuracy: 0.8679\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_29 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_29  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=64__optimizer=adam__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 3s 18ms/step - loss: 0.6664 - accuracy: 0.5984 - val_loss: 0.5997 - val_accuracy: 0.7472\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 0.5254 - accuracy: 0.7872 - val_loss: 0.4358 - val_accuracy: 0.8324\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.3968 - accuracy: 0.8446 - val_loss: 0.3597 - val_accuracy: 0.8523\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.3772 - accuracy: 0.8452\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=64__optimizer=adam__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_30 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_30  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 20ms/step - loss: 0.5104 - accuracy: 0.7525 - val_loss: 0.3335 - val_accuracy: 0.8651\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.3366 - accuracy: 0.8735 - val_loss: 0.5737 - val_accuracy: 0.7983\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 0.4376 - accuracy: 0.8785 - val_loss: 0.5827 - val_accuracy: 0.8295\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.4475 - accuracy: 0.8665\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_31 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_31  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=64__optimizer=adam__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 20ms/step - loss: 0.5151 - accuracy: 0.7589 - val_loss: 0.3689 - val_accuracy: 0.8679\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.3532 - accuracy: 0.8645 - val_loss: 0.3997 - val_accuracy: 0.8622\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.3279 - accuracy: 0.8891 - val_loss: 0.4897 - val_accuracy: 0.8423\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.5113 - accuracy: 0.8381\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=64__optimizer=adam__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_32 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_32  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 22ms/step - loss: 0.5105 - accuracy: 0.7602 - val_loss: 0.3485 - val_accuracy: 0.8352\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.3187 - accuracy: 0.8743 - val_loss: 0.3786 - val_accuracy: 0.8722\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.3102 - accuracy: 0.8965 - val_loss: 0.7480 - val_accuracy: 0.8224\n",
      "11/11 [==============================] - 2s 2ms/step - loss: 0.7439 - accuracy: 0.8068\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_33 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_33  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=64__optimizer=adam__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 21ms/step - loss: 0.5047 - accuracy: 0.7620 - val_loss: 0.3851 - val_accuracy: 0.8324\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 0.3559 - accuracy: 0.8599 - val_loss: 0.8263 - val_accuracy: 0.7884\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 0.3880 - accuracy: 0.8758 - val_loss: 0.8082 - val_accuracy: 0.8040\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.6422 - accuracy: 0.8153\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=64__optimizer=adam__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_34 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_34  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 20ms/step - loss: 0.5175 - accuracy: 0.7503 - val_loss: 0.3161 - val_accuracy: 0.8707\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.3409 - accuracy: 0.8633 - val_loss: 0.3949 - val_accuracy: 0.8778\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.3721 - accuracy: 0.8877 - val_loss: 0.6164 - val_accuracy: 0.8409\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.5791 - accuracy: 0.8352\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_35 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_35  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=64__optimizer=adam__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 20ms/step - loss: 0.5146 - accuracy: 0.7605 - val_loss: 0.3664 - val_accuracy: 0.8281\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.3404 - accuracy: 0.8684 - val_loss: 0.7394 - val_accuracy: 0.8324\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 0.4213 - accuracy: 0.8738 - val_loss: 0.4693 - val_accuracy: 0.8011\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.3994 - accuracy: 0.8111\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=64__optimizer=adam__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_36 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_36  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 5s 7ms/step - loss: 0.5593 - accuracy: 0.6923 - val_loss: 0.4136 - val_accuracy: 0.8165\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 0.3654 - accuracy: 0.8433 - val_loss: 0.3363 - val_accuracy: 0.8630\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 0.2942 - accuracy: 0.8801 - val_loss: 0.2896 - val_accuracy: 0.8830\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 0.3217 - accuracy: 0.8763\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_37 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_37  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=16__optimizer=adam__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 5s 8ms/step - loss: 0.5543 - accuracy: 0.7174 - val_loss: 0.3781 - val_accuracy: 0.8577\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 0.3650 - accuracy: 0.8500 - val_loss: 0.3107 - val_accuracy: 0.8856\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 0.2978 - accuracy: 0.8862 - val_loss: 0.2845 - val_accuracy: 0.8949\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 0.2711 - accuracy: 0.8936\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=16__optimizer=adam__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_38 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_38  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 5s 8ms/step - loss: 0.5525 - accuracy: 0.7002 - val_loss: 0.3941 - val_accuracy: 0.8351\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 0.3646 - accuracy: 0.8424 - val_loss: 0.3188 - val_accuracy: 0.8777\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 0.2950 - accuracy: 0.8799 - val_loss: 0.2835 - val_accuracy: 0.9029\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 0.2852 - accuracy: 0.8883\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_39 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_39  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=16__optimizer=adam__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 5s 8ms/step - loss: 0.5574 - accuracy: 0.7373 - val_loss: 0.3809 - val_accuracy: 0.8564\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 0.3646 - accuracy: 0.8469 - val_loss: 0.3095 - val_accuracy: 0.8856\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 0.2902 - accuracy: 0.8844 - val_loss: 0.2785 - val_accuracy: 0.9056\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 0.2884 - accuracy: 0.8949\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=16__optimizer=adam__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_40 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_40  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 5s 8ms/step - loss: 0.5654 - accuracy: 0.6816 - val_loss: 0.3958 - val_accuracy: 0.8218\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 0.3737 - accuracy: 0.8375 - val_loss: 0.3151 - val_accuracy: 0.8697\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 0.3029 - accuracy: 0.8789 - val_loss: 0.2644 - val_accuracy: 0.9003\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 0.2718 - accuracy: 0.8976\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_41 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_41  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=16__optimizer=adam__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 5s 8ms/step - loss: 0.5663 - accuracy: 0.7079 - val_loss: 0.3846 - val_accuracy: 0.8484\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 0.3772 - accuracy: 0.8400 - val_loss: 0.3137 - val_accuracy: 0.8790\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 0.3091 - accuracy: 0.8788 - val_loss: 0.2753 - val_accuracy: 0.8989\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 0.3150 - accuracy: 0.8803\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=16__optimizer=adam__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_42 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_42  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 5s 8ms/step - loss: 0.5881 - accuracy: 0.7347 - val_loss: 0.5751 - val_accuracy: 0.7354\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 1.1860 - accuracy: 0.8107 - val_loss: 1.4832 - val_accuracy: 0.7394\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 0.9975 - accuracy: 0.8454 - val_loss: 1.7245 - val_accuracy: 0.7726\n",
      "47/47 [==============================] - 2s 1ms/step - loss: 1.8665 - accuracy: 0.7886\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_43 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_43  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=16__optimizer=adam__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 5s 8ms/step - loss: 0.6110 - accuracy: 0.7217 - val_loss: 0.4265 - val_accuracy: 0.8205\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 1.1197 - accuracy: 0.8021 - val_loss: 4.1821 - val_accuracy: 0.4535\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 1.9734 - accuracy: 0.8113 - val_loss: 4.0478 - val_accuracy: 0.8072\n",
      "47/47 [==============================] - 2s 1ms/step - loss: 4.1407 - accuracy: 0.8019\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=16__optimizer=adam__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_44 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_44  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 5s 7ms/step - loss: 0.5972 - accuracy: 0.7362 - val_loss: 0.4791 - val_accuracy: 0.7886\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 1.3489 - accuracy: 0.8010 - val_loss: 1.3810 - val_accuracy: 0.7726\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 1.1328 - accuracy: 0.8387 - val_loss: 1.7753 - val_accuracy: 0.7992\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 1.7905 - accuracy: 0.7859\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_45 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_45  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=16__optimizer=adam__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 5s 7ms/step - loss: 0.6383 - accuracy: 0.7179 - val_loss: 0.4669 - val_accuracy: 0.7886\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 0.9361 - accuracy: 0.8049 - val_loss: 1.1580 - val_accuracy: 0.8258\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 1.0340 - accuracy: 0.8390 - val_loss: 1.5827 - val_accuracy: 0.8271\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 1.8841 - accuracy: 0.8072\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=16__optimizer=adam__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_46 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_46  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 4s 7ms/step - loss: 0.6334 - accuracy: 0.7234 - val_loss: 0.4301 - val_accuracy: 0.8045\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 1.2225 - accuracy: 0.8046 - val_loss: 1.9238 - val_accuracy: 0.6702\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 1.3235 - accuracy: 0.8398 - val_loss: 2.3696 - val_accuracy: 0.8005\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 2.4486 - accuracy: 0.7899\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_47 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_47  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=16__optimizer=adam__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 4s 7ms/step - loss: 0.6434 - accuracy: 0.7220 - val_loss: 0.4963 - val_accuracy: 0.7513\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 1.2769 - accuracy: 0.7911 - val_loss: 0.8234 - val_accuracy: 0.8191\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 1.3713 - accuracy: 0.8211 - val_loss: 2.5690 - val_accuracy: 0.8338\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 2.4961 - accuracy: 0.8324\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=16__optimizer=adam__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_48 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_48  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 11ms/step - loss: 0.6230 - accuracy: 0.6253 - val_loss: 0.4438 - val_accuracy: 0.8234\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4086 - accuracy: 0.8206 - val_loss: 0.3285 - val_accuracy: 0.8668\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3292 - accuracy: 0.8641 - val_loss: 0.2812 - val_accuracy: 0.8886\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.2943 - accuracy: 0.8764\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_49 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_49  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=32__optimizer=adam__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 11ms/step - loss: 0.6127 - accuracy: 0.6715 - val_loss: 0.4490 - val_accuracy: 0.8207\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4004 - accuracy: 0.8278 - val_loss: 0.3512 - val_accuracy: 0.8641\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3242 - accuracy: 0.8681 - val_loss: 0.3129 - val_accuracy: 0.8899\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.2966 - accuracy: 0.8995\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=32__optimizer=adam__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_50 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_50  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_100 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 10ms/step - loss: 0.6223 - accuracy: 0.6385 - val_loss: 0.4516 - val_accuracy: 0.8152\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4010 - accuracy: 0.8232 - val_loss: 0.3379 - val_accuracy: 0.8655\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3229 - accuracy: 0.8669 - val_loss: 0.2854 - val_accuracy: 0.8967\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.3243 - accuracy: 0.8750\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_51 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_51  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=32__optimizer=adam__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 10ms/step - loss: 0.6173 - accuracy: 0.6625 - val_loss: 0.4564 - val_accuracy: 0.8315\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4085 - accuracy: 0.8311 - val_loss: 0.3317 - val_accuracy: 0.8614\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3237 - accuracy: 0.8658 - val_loss: 0.2845 - val_accuracy: 0.8859\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.3087 - accuracy: 0.8777\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=32__optimizer=adam__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_52 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_52  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_104 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 10ms/step - loss: 0.6123 - accuracy: 0.6434 - val_loss: 0.4624 - val_accuracy: 0.7948\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3977 - accuracy: 0.8273 - val_loss: 0.3511 - val_accuracy: 0.8546\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3194 - accuracy: 0.8689 - val_loss: 0.3058 - val_accuracy: 0.8764\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.2907 - accuracy: 0.8954\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_53 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_53  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=32__optimizer=adam__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 10ms/step - loss: 0.6033 - accuracy: 0.6798 - val_loss: 0.4443 - val_accuracy: 0.8179\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4000 - accuracy: 0.8329 - val_loss: 0.3278 - val_accuracy: 0.8573\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3220 - accuracy: 0.8711 - val_loss: 0.2833 - val_accuracy: 0.8886\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.3137 - accuracy: 0.8736\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=32__optimizer=adam__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_54 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_54  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 10ms/step - loss: 0.5330 - accuracy: 0.7472 - val_loss: 0.4044 - val_accuracy: 0.8166\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.5791 - accuracy: 0.8336 - val_loss: 0.8643 - val_accuracy: 0.8356\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.7065 - accuracy: 0.8475 - val_loss: 2.3015 - val_accuracy: 0.8356\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 2.8292 - accuracy: 0.8342\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_55 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_55  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=32__optimizer=adam__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 10ms/step - loss: 0.5520 - accuracy: 0.7503 - val_loss: 0.4191 - val_accuracy: 0.8370\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.5763 - accuracy: 0.8362 - val_loss: 0.7088 - val_accuracy: 0.8261\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.9896 - accuracy: 0.8535 - val_loss: 1.5616 - val_accuracy: 0.7894\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 1.0752 - accuracy: 0.7880\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=32__optimizer=adam__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_56 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_56  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 11ms/step - loss: 0.5459 - accuracy: 0.7433 - val_loss: 0.3769 - val_accuracy: 0.8383\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.5289 - accuracy: 0.8507 - val_loss: 1.0444 - val_accuracy: 0.8071\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.7336 - accuracy: 0.8587 - val_loss: 1.3369 - val_accuracy: 0.7622\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 1.1605 - accuracy: 0.7935\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_57 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_57  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_57 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=32__optimizer=adam__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 11ms/step - loss: 0.5302 - accuracy: 0.7457 - val_loss: 0.3629 - val_accuracy: 0.8533\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.6296 - accuracy: 0.8227 - val_loss: 1.2134 - val_accuracy: 0.7840\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.8432 - accuracy: 0.8495 - val_loss: 1.8749 - val_accuracy: 0.8166\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 2.1157 - accuracy: 0.8003\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=32__optimizer=adam__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_58 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_58  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 10ms/step - loss: 0.5495 - accuracy: 0.7416 - val_loss: 0.4197 - val_accuracy: 0.8098\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.5670 - accuracy: 0.8313 - val_loss: 0.7493 - val_accuracy: 0.7690\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.5931 - accuracy: 0.8571 - val_loss: 0.8875 - val_accuracy: 0.7867\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.6257 - accuracy: 0.8043\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_59 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_59  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=32__optimizer=adam__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 11ms/step - loss: 0.5393 - accuracy: 0.7553 - val_loss: 0.3682 - val_accuracy: 0.8478\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.6628 - accuracy: 0.8265 - val_loss: 1.0898 - val_accuracy: 0.8220\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.8919 - accuracy: 0.8354 - val_loss: 1.0113 - val_accuracy: 0.8030\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.7167 - accuracy: 0.8098\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=32__optimizer=adam__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_60 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_60  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_120 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 3s 18ms/step - loss: 0.6647 - accuracy: 0.5814 - val_loss: 0.6151 - val_accuracy: 0.6307\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 0.4901 - accuracy: 0.7656 - val_loss: 0.4152 - val_accuracy: 0.8366\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 0.3681 - accuracy: 0.8438 - val_loss: 0.3441 - val_accuracy: 0.8679\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.3588 - accuracy: 0.8480\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_61 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_61  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=64__optimizer=adam__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 3s 19ms/step - loss: 0.6615 - accuracy: 0.6092 - val_loss: 0.5854 - val_accuracy: 0.7401\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.4923 - accuracy: 0.8023 - val_loss: 0.3955 - val_accuracy: 0.8494\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 0.3721 - accuracy: 0.8451 - val_loss: 0.3334 - val_accuracy: 0.8636\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.3630 - accuracy: 0.8565\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=64__optimizer=adam__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_62 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_62  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_62 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 3s 19ms/step - loss: 0.6684 - accuracy: 0.5819 - val_loss: 0.6115 - val_accuracy: 0.6378\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 0.4916 - accuracy: 0.7610 - val_loss: 0.4097 - val_accuracy: 0.8295\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 0.3687 - accuracy: 0.8418 - val_loss: 0.3578 - val_accuracy: 0.8665\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.3733 - accuracy: 0.8494\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_63 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_63  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_63 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=64__optimizer=adam__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 20ms/step - loss: 0.6638 - accuracy: 0.6245 - val_loss: 0.5892 - val_accuracy: 0.7656\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.4842 - accuracy: 0.8090 - val_loss: 0.4060 - val_accuracy: 0.8395\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.3685 - accuracy: 0.8510 - val_loss: 0.3558 - val_accuracy: 0.8580\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.3085 - accuracy: 0.8707\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=64__optimizer=adam__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_64 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_64  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_64 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 19ms/step - loss: 0.6608 - accuracy: 0.5844 - val_loss: 0.5933 - val_accuracy: 0.6761\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.4860 - accuracy: 0.7689 - val_loss: 0.4057 - val_accuracy: 0.8366\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.3655 - accuracy: 0.8451 - val_loss: 0.3392 - val_accuracy: 0.8622\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.3181 - accuracy: 0.8665\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_65 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_65  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_65 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_130 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=64__optimizer=adam__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 19ms/step - loss: 0.6596 - accuracy: 0.5926 - val_loss: 0.5849 - val_accuracy: 0.7244\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.4990 - accuracy: 0.7933 - val_loss: 0.3831 - val_accuracy: 0.8494\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.3708 - accuracy: 0.8502 - val_loss: 0.3232 - val_accuracy: 0.8594\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.3328 - accuracy: 0.8608\n",
      "run=0__lr=0.001__hidden_unit=16__batch_size=64__optimizer=adam__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_66 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_66  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_66 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_133 (Dense)           (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 23ms/step - loss: 0.5076 - accuracy: 0.7620 - val_loss: 0.3856 - val_accuracy: 0.8224\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.4244 - accuracy: 0.8637 - val_loss: 0.4724 - val_accuracy: 0.8224\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.5347 - accuracy: 0.8651 - val_loss: 0.9833 - val_accuracy: 0.7955\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.9573 - accuracy: 0.8026\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_67 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_67  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_67 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=64__optimizer=adam__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 20ms/step - loss: 0.5162 - accuracy: 0.7587 - val_loss: 0.4263 - val_accuracy: 0.8395\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.3797 - accuracy: 0.8691 - val_loss: 0.4965 - val_accuracy: 0.8324\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.4453 - accuracy: 0.8817 - val_loss: 1.4561 - val_accuracy: 0.8097\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 1.6496 - accuracy: 0.7756\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=64__optimizer=adam__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_68 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_68  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_68 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_136 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 20ms/step - loss: 0.5149 - accuracy: 0.7528 - val_loss: 0.3728 - val_accuracy: 0.8466\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.3748 - accuracy: 0.8687 - val_loss: 0.8401 - val_accuracy: 0.8153\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.5387 - accuracy: 0.8813 - val_loss: 1.7501 - val_accuracy: 0.8168\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 1.3629 - accuracy: 0.8452\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_69 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_69  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_69 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_139 (Dense)           (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=64__optimizer=adam__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 20ms/step - loss: 0.5109 - accuracy: 0.7600 - val_loss: 0.3355 - val_accuracy: 0.8622\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.3498 - accuracy: 0.8709 - val_loss: 0.6888 - val_accuracy: 0.7855\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.4706 - accuracy: 0.8854 - val_loss: 1.3065 - val_accuracy: 0.6392\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 1.5154 - accuracy: 0.6151\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=64__optimizer=adam__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_70 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_70  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_70 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_140 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 22ms/step - loss: 0.5117 - accuracy: 0.7554 - val_loss: 0.3651 - val_accuracy: 0.8523\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.4500 - accuracy: 0.8452 - val_loss: 0.4535 - val_accuracy: 0.8295\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.4463 - accuracy: 0.8668 - val_loss: 0.6297 - val_accuracy: 0.8736\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.5774 - accuracy: 0.8537\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_71 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_71  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_71 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_142 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,138\n",
      "Trainable params: 321,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=64__optimizer=adam__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 22ms/step - loss: 0.5218 - accuracy: 0.7526 - val_loss: 0.3256 - val_accuracy: 0.8622\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.3702 - accuracy: 0.8714 - val_loss: 0.7358 - val_accuracy: 0.7202\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.5413 - accuracy: 0.8697 - val_loss: 1.0370 - val_accuracy: 0.7869\n",
      "11/11 [==============================] - 2s 2ms/step - loss: 1.1236 - accuracy: 0.7543\n",
      "run=0__lr=0.1__hidden_unit=16__batch_size=64__optimizer=adam__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_72 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_72  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_72 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_144 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_145 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 5s 8ms/step - loss: 0.5509 - accuracy: 0.7026 - val_loss: 0.3763 - val_accuracy: 0.8577\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 0.3627 - accuracy: 0.8472 - val_loss: 0.3118 - val_accuracy: 0.8883\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 0.2918 - accuracy: 0.8857 - val_loss: 0.2853 - val_accuracy: 0.9069\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 0.3017 - accuracy: 0.8843\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_73 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_73  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_73 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=16__optimizer=adam__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 5s 7ms/step - loss: 0.5463 - accuracy: 0.7243 - val_loss: 0.3562 - val_accuracy: 0.8551\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 0.3652 - accuracy: 0.8484 - val_loss: 0.2904 - val_accuracy: 0.8963\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 0.2953 - accuracy: 0.8867 - val_loss: 0.2582 - val_accuracy: 0.9109\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 0.2956 - accuracy: 0.8936\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=16__optimizer=adam__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_74 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_74  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_74 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_148 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 4s 7ms/step - loss: 0.5469 - accuracy: 0.7015 - val_loss: 0.4311 - val_accuracy: 0.8138\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 0.3583 - accuracy: 0.8452 - val_loss: 0.3556 - val_accuracy: 0.8590\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 0.2860 - accuracy: 0.8860 - val_loss: 0.3167 - val_accuracy: 0.8856\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 0.3020 - accuracy: 0.8896\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_75 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_75  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_75 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_150 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=16__optimizer=adam__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 4s 7ms/step - loss: 0.5395 - accuracy: 0.7441 - val_loss: 0.3821 - val_accuracy: 0.8418\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 0.3690 - accuracy: 0.8493 - val_loss: 0.3119 - val_accuracy: 0.8763\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 0.3035 - accuracy: 0.8801 - val_loss: 0.2744 - val_accuracy: 0.8963\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 0.2338 - accuracy: 0.9043\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=16__optimizer=adam__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_76 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_76  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_76 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_152 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 4s 7ms/step - loss: 0.5460 - accuracy: 0.7048 - val_loss: 0.3755 - val_accuracy: 0.8511\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 0.3619 - accuracy: 0.8451 - val_loss: 0.3162 - val_accuracy: 0.8830\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 0.2919 - accuracy: 0.8826 - val_loss: 0.2891 - val_accuracy: 0.9029\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 0.2894 - accuracy: 0.8963\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_77 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_77  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_77 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_154 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_155 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=16__optimizer=adam__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 4s 7ms/step - loss: 0.5361 - accuracy: 0.7283 - val_loss: 0.3793 - val_accuracy: 0.8431\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 0.3568 - accuracy: 0.8510 - val_loss: 0.3166 - val_accuracy: 0.8750\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 0.2892 - accuracy: 0.8847 - val_loss: 0.2784 - val_accuracy: 0.8910\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 0.2917 - accuracy: 0.8949\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=16__optimizer=adam__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_78 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_78  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_78 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_156 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 4s 7ms/step - loss: 0.7305 - accuracy: 0.7095 - val_loss: 0.7883 - val_accuracy: 0.6795\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 1.8928 - accuracy: 0.8061 - val_loss: 3.4130 - val_accuracy: 0.7287\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 3.3423 - accuracy: 0.8326 - val_loss: 4.5736 - val_accuracy: 0.7859\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 4.4306 - accuracy: 0.7713\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_79 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_79  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_79 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_158 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=16__optimizer=adam__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 4s 7ms/step - loss: 0.7346 - accuracy: 0.6988 - val_loss: 0.8327 - val_accuracy: 0.8045\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 2.9218 - accuracy: 0.7816 - val_loss: 3.6124 - val_accuracy: 0.7806\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 2.9826 - accuracy: 0.8314 - val_loss: 6.9224 - val_accuracy: 0.8112\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 6.9495 - accuracy: 0.8205\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=16__optimizer=adam__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_80 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_80  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_80 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_160 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 4s 7ms/step - loss: 0.7441 - accuracy: 0.7012 - val_loss: 0.7457 - val_accuracy: 0.7048\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 1.7331 - accuracy: 0.7918 - val_loss: 2.6256 - val_accuracy: 0.7912\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 2.9567 - accuracy: 0.8373 - val_loss: 5.7103 - val_accuracy: 0.8032\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 6.6596 - accuracy: 0.8098\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_81 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_81  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_81 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_162 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=16__optimizer=adam__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 4s 7ms/step - loss: 0.7184 - accuracy: 0.7071 - val_loss: 0.5401 - val_accuracy: 0.7340\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 3.1126 - accuracy: 0.7988 - val_loss: 6.0414 - val_accuracy: 0.7660\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 3.2037 - accuracy: 0.8178 - val_loss: 3.3568 - val_accuracy: 0.7859\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 3.7752 - accuracy: 0.7713\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=16__optimizer=adam__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_82 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_82  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_82 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_164 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 4s 7ms/step - loss: 0.7625 - accuracy: 0.6975 - val_loss: 0.9160 - val_accuracy: 0.6037\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 2.5125 - accuracy: 0.7906 - val_loss: 3.0773 - val_accuracy: 0.6981\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 2.8603 - accuracy: 0.8188 - val_loss: 4.8064 - val_accuracy: 0.7194\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 4.7867 - accuracy: 0.7181\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_83 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_83  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_83 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_166 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=16__optimizer=adam__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 4s 7ms/step - loss: 0.7867 - accuracy: 0.6965 - val_loss: 0.9681 - val_accuracy: 0.7354\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 2.8848 - accuracy: 0.7776 - val_loss: 6.6979 - val_accuracy: 0.8059\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 4.0944 - accuracy: 0.8146 - val_loss: 3.9716 - val_accuracy: 0.7872\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 3.6479 - accuracy: 0.8032\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=16__optimizer=adam__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_84 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_84  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_84 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 11ms/step - loss: 0.6021 - accuracy: 0.6528 - val_loss: 0.4236 - val_accuracy: 0.8247\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3848 - accuracy: 0.8352 - val_loss: 0.3287 - val_accuracy: 0.8614\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3062 - accuracy: 0.8737 - val_loss: 0.2848 - val_accuracy: 0.8804\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.2741 - accuracy: 0.8940\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_85 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_85  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_85 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_170 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=32__optimizer=adam__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 11ms/step - loss: 0.5940 - accuracy: 0.6859 - val_loss: 0.4137 - val_accuracy: 0.8261\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3886 - accuracy: 0.8340 - val_loss: 0.3336 - val_accuracy: 0.8614\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3141 - accuracy: 0.8783 - val_loss: 0.2962 - val_accuracy: 0.8845\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.2644 - accuracy: 0.8995\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=32__optimizer=adam__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_86 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_86  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_86 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_172 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 11ms/step - loss: 0.5955 - accuracy: 0.6548 - val_loss: 0.4332 - val_accuracy: 0.8179\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3892 - accuracy: 0.8308 - val_loss: 0.3544 - val_accuracy: 0.8533\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3112 - accuracy: 0.8706 - val_loss: 0.3207 - val_accuracy: 0.8750\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.3107 - accuracy: 0.8832\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_87 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_87  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_87 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=32__optimizer=adam__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 11ms/step - loss: 0.5859 - accuracy: 0.6944 - val_loss: 0.4058 - val_accuracy: 0.8315\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3831 - accuracy: 0.8372 - val_loss: 0.3108 - val_accuracy: 0.8791\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3114 - accuracy: 0.8747 - val_loss: 0.2588 - val_accuracy: 0.9103\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.3012 - accuracy: 0.8899\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=32__optimizer=adam__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_88 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_88  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_88 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_176 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_177 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 11ms/step - loss: 0.6026 - accuracy: 0.6604 - val_loss: 0.4464 - val_accuracy: 0.7976\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3855 - accuracy: 0.8337 - val_loss: 0.3402 - val_accuracy: 0.8641\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 0.3093 - accuracy: 0.8763 - val_loss: 0.2971 - val_accuracy: 0.8872\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.2866 - accuracy: 0.8913\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_89 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_89  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_89 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_178 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_179 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=32__optimizer=adam__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 11ms/step - loss: 0.5925 - accuracy: 0.6801 - val_loss: 0.4084 - val_accuracy: 0.8329\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3858 - accuracy: 0.8398 - val_loss: 0.3212 - val_accuracy: 0.8573\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3116 - accuracy: 0.8743 - val_loss: 0.2708 - val_accuracy: 0.8913\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.2594 - accuracy: 0.9185\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=32__optimizer=adam__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_90 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_90  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_90 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_180 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_181 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 11ms/step - loss: 0.5804 - accuracy: 0.7441 - val_loss: 0.5275 - val_accuracy: 0.7690\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.9368 - accuracy: 0.8123 - val_loss: 1.4731 - val_accuracy: 0.8274\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 1.9780 - accuracy: 0.8253 - val_loss: 2.7511 - val_accuracy: 0.8071\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 3.0875 - accuracy: 0.8125\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_91\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_91 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_91  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_91 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_182 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_183 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=32__optimizer=adam__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 10ms/step - loss: 0.5612 - accuracy: 0.7536 - val_loss: 0.3926 - val_accuracy: 0.8424\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.9479 - accuracy: 0.8375 - val_loss: 1.5873 - val_accuracy: 0.8057\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 1.6368 - accuracy: 0.8311 - val_loss: 8.3243 - val_accuracy: 0.7908\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 7.6075 - accuracy: 0.7962\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=32__optimizer=adam__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_92 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_92  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_92 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_184 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_185 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 11ms/step - loss: 0.5662 - accuracy: 0.7337 - val_loss: 0.4419 - val_accuracy: 0.8342\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 1.0840 - accuracy: 0.8112 - val_loss: 1.0776 - val_accuracy: 0.7921\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 1.0692 - accuracy: 0.8444 - val_loss: 3.1653 - val_accuracy: 0.8043\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 3.3128 - accuracy: 0.8465\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_93\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_93 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_93  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_93 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_186 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_187 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=32__optimizer=adam__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 10ms/step - loss: 0.5398 - accuracy: 0.7475 - val_loss: 0.3579 - val_accuracy: 0.8573\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.7551 - accuracy: 0.8339 - val_loss: 2.0731 - val_accuracy: 0.6562\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 1.5760 - accuracy: 0.8359 - val_loss: 6.0514 - val_accuracy: 0.6196\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 6.3759 - accuracy: 0.6304\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=32__optimizer=adam__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_94 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_94  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_94 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_188 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_189 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 11ms/step - loss: 0.5904 - accuracy: 0.7373 - val_loss: 0.3750 - val_accuracy: 0.8492\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.9865 - accuracy: 0.8164 - val_loss: 1.0559 - val_accuracy: 0.8030\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 1.1943 - accuracy: 0.8378 - val_loss: 1.3599 - val_accuracy: 0.8601\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 2.1275 - accuracy: 0.8261\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_95\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_95 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_95  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_95 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_190 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_191 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=32__optimizer=adam__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 10ms/step - loss: 0.5646 - accuracy: 0.7447 - val_loss: 0.3898 - val_accuracy: 0.8410\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.9150 - accuracy: 0.8225 - val_loss: 1.2703 - val_accuracy: 0.7337\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 1.8583 - accuracy: 0.8285 - val_loss: 2.3888 - val_accuracy: 0.7962\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 2.2160 - accuracy: 0.8234\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=32__optimizer=adam__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_96\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_96 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_96  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_96 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_192 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_193 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 3s 18ms/step - loss: 0.6591 - accuracy: 0.5809 - val_loss: 0.5759 - val_accuracy: 0.6960\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 0.4512 - accuracy: 0.8008 - val_loss: 0.3817 - val_accuracy: 0.8509\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.3432 - accuracy: 0.8566 - val_loss: 0.3209 - val_accuracy: 0.8736\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.3634 - accuracy: 0.8551\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_97\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_97 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_97  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_97 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_194 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_195 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=64__optimizer=adam__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 3s 17ms/step - loss: 0.6444 - accuracy: 0.6345 - val_loss: 0.5206 - val_accuracy: 0.8068\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.8245 - val_loss: 0.3607 - val_accuracy: 0.8580\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 0.3373 - accuracy: 0.8673 - val_loss: 0.3139 - val_accuracy: 0.8807\n",
      "11/11 [==============================] - 1s 1ms/step - loss: 0.2938 - accuracy: 0.8878\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=64__optimizer=adam__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_98\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_98 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_98  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_98 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_196 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_197 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 3s 17ms/step - loss: 0.6602 - accuracy: 0.5826 - val_loss: 0.5713 - val_accuracy: 0.7003\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.4487 - accuracy: 0.7952 - val_loss: 0.3721 - val_accuracy: 0.8352\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 0.3440 - accuracy: 0.8597 - val_loss: 0.3204 - val_accuracy: 0.8707\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.3184 - accuracy: 0.8608\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_99\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_99 (Embedding)    (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_99  (None, 64)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_99 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_198 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_199 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=64__optimizer=adam__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 3s 20ms/step - loss: 0.6445 - accuracy: 0.6268 - val_loss: 0.5267 - val_accuracy: 0.8153\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.4440 - accuracy: 0.8192 - val_loss: 0.3409 - val_accuracy: 0.8665\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.3425 - accuracy: 0.8638 - val_loss: 0.2837 - val_accuracy: 0.8920\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.3181 - accuracy: 0.8736\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=64__optimizer=adam__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_100\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_100 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_10  (None, 64)               0         \n",
      " 0 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_100 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_200 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_201 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 20ms/step - loss: 0.6604 - accuracy: 0.5868 - val_loss: 0.5798 - val_accuracy: 0.6946\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.4563 - accuracy: 0.7936 - val_loss: 0.3806 - val_accuracy: 0.8466\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.3470 - accuracy: 0.8549 - val_loss: 0.3266 - val_accuracy: 0.8793\n",
      "11/11 [==============================] - 2s 2ms/step - loss: 0.3181 - accuracy: 0.8778\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_101\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_101 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_10  (None, 64)               0         \n",
      " 1 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_101 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_202 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_203 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=64__optimizer=adam__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 22ms/step - loss: 0.6557 - accuracy: 0.6183 - val_loss: 0.5476 - val_accuracy: 0.7969\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.4473 - accuracy: 0.8179 - val_loss: 0.3647 - val_accuracy: 0.8466\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.3464 - accuracy: 0.8564 - val_loss: 0.3136 - val_accuracy: 0.8665\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.3449 - accuracy: 0.8580\n",
      "run=0__lr=0.001__hidden_unit=32__batch_size=64__optimizer=adam__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_102\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_102 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_10  (None, 64)               0         \n",
      " 2 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_102 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_204 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_205 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 22ms/step - loss: 0.5253 - accuracy: 0.7523 - val_loss: 0.3938 - val_accuracy: 0.8381\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.5384 - accuracy: 0.8484 - val_loss: 1.1998 - val_accuracy: 0.8011\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.6629 - accuracy: 0.8687 - val_loss: 1.3582 - val_accuracy: 0.8026\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 1.8009 - accuracy: 0.8054\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_103\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_103 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_10  (None, 64)               0         \n",
      " 3 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_103 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_206 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_207 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=64__optimizer=adam__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 21ms/step - loss: 0.5303 - accuracy: 0.7533 - val_loss: 0.3831 - val_accuracy: 0.8224\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.5113 - accuracy: 0.8604 - val_loss: 1.0958 - val_accuracy: 0.8097\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.9521 - accuracy: 0.8500 - val_loss: 1.4560 - val_accuracy: 0.7983\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 1.4400 - accuracy: 0.7727\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=64__optimizer=adam__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_104\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_104 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_10  (None, 64)               0         \n",
      " 4 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_104 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_208 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_209 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 22ms/step - loss: 0.5273 - accuracy: 0.7408 - val_loss: 0.3567 - val_accuracy: 0.8580\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.4790 - accuracy: 0.8548 - val_loss: 0.8484 - val_accuracy: 0.6847\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.6705 - accuracy: 0.8737 - val_loss: 1.2452 - val_accuracy: 0.8210\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 1.3958 - accuracy: 0.8026\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_105\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_105 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_10  (None, 64)               0         \n",
      " 5 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_105 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_210 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_211 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=64__optimizer=adam__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 23ms/step - loss: 0.5428 - accuracy: 0.7475 - val_loss: 0.4019 - val_accuracy: 0.8438\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.4780 - accuracy: 0.8544 - val_loss: 0.6881 - val_accuracy: 0.7812\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 1.1726 - accuracy: 0.8416 - val_loss: 1.4964 - val_accuracy: 0.7983\n",
      "11/11 [==============================] - 2s 2ms/step - loss: 1.3200 - accuracy: 0.8310\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=64__optimizer=adam__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_106\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_106 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_10  (None, 64)               0         \n",
      " 6 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_106 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_212 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_213 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 20ms/step - loss: 0.5200 - accuracy: 0.7599 - val_loss: 0.3357 - val_accuracy: 0.8551\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.5207 - accuracy: 0.8526 - val_loss: 1.0066 - val_accuracy: 0.8537\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.8594 - accuracy: 0.8602 - val_loss: 1.1531 - val_accuracy: 0.8381\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 1.2320 - accuracy: 0.8182\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_107\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_107 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_10  (None, 64)               0         \n",
      " 7 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_107 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_214 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_215 (Dense)           (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,210\n",
      "Trainable params: 322,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=64__optimizer=adam__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 21ms/step - loss: 0.5427 - accuracy: 0.7429 - val_loss: 0.4187 - val_accuracy: 0.8224\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.5318 - accuracy: 0.8408 - val_loss: 0.6083 - val_accuracy: 0.8352\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.6660 - accuracy: 0.8692 - val_loss: 1.1266 - val_accuracy: 0.8480\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 1.2075 - accuracy: 0.8523\n",
      "run=0__lr=0.1__hidden_unit=32__batch_size=64__optimizer=adam__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_108\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_108 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_10  (None, 64)               0         \n",
      " 8 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_108 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_216 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_217 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 5s 7ms/step - loss: 0.5420 - accuracy: 0.7099 - val_loss: 0.3818 - val_accuracy: 0.8484\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 0.3690 - accuracy: 0.8429 - val_loss: 0.3151 - val_accuracy: 0.8763\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 0.3001 - accuracy: 0.8786 - val_loss: 0.2747 - val_accuracy: 0.9016\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 0.2924 - accuracy: 0.8790\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_109\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_109 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_10  (None, 64)               0         \n",
      " 9 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_109 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_218 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_219 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=16__optimizer=adam__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 5s 8ms/step - loss: 0.5341 - accuracy: 0.7278 - val_loss: 0.3424 - val_accuracy: 0.8670\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 0.3524 - accuracy: 0.8541 - val_loss: 0.2777 - val_accuracy: 0.8896\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 0.2838 - accuracy: 0.8900 - val_loss: 0.2416 - val_accuracy: 0.9122\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 0.2619 - accuracy: 0.9096\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=16__optimizer=adam__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_110\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_110 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_11  (None, 64)               0         \n",
      " 0 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_110 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_220 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_221 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 5s 8ms/step - loss: 0.5337 - accuracy: 0.7209 - val_loss: 0.4106 - val_accuracy: 0.8138\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 0.3604 - accuracy: 0.8449 - val_loss: 0.3351 - val_accuracy: 0.8604\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 0.2918 - accuracy: 0.8817 - val_loss: 0.2935 - val_accuracy: 0.8816\n",
      "47/47 [==============================] - 2s 1ms/step - loss: 0.2833 - accuracy: 0.8936\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_111\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_111 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_11  (None, 64)               0         \n",
      " 1 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_111 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_222 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_223 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=16__optimizer=adam__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 5s 9ms/step - loss: 0.5434 - accuracy: 0.7283 - val_loss: 0.3773 - val_accuracy: 0.8404\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 0.3707 - accuracy: 0.8464 - val_loss: 0.3015 - val_accuracy: 0.8896\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 0.3030 - accuracy: 0.8844 - val_loss: 0.2639 - val_accuracy: 0.9029\n",
      "47/47 [==============================] - 2s 1ms/step - loss: 0.2424 - accuracy: 0.9043\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=16__optimizer=adam__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_112\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_112 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_11  (None, 64)               0         \n",
      " 2 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_112 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_224 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_225 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 5s 8ms/step - loss: 0.5384 - accuracy: 0.7145 - val_loss: 0.3710 - val_accuracy: 0.8457\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 0.3605 - accuracy: 0.8475 - val_loss: 0.3023 - val_accuracy: 0.8816\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 0.2926 - accuracy: 0.8826 - val_loss: 0.2631 - val_accuracy: 0.9029\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 0.2643 - accuracy: 0.9016\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_113\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_113 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_11  (None, 64)               0         \n",
      " 3 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_113 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_226 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_227 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=16__optimizer=adam__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 5s 8ms/step - loss: 0.5373 - accuracy: 0.7252 - val_loss: 0.3584 - val_accuracy: 0.8551\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 0.3587 - accuracy: 0.8487 - val_loss: 0.2960 - val_accuracy: 0.8816\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 0.2908 - accuracy: 0.8859 - val_loss: 0.2690 - val_accuracy: 0.9029\n",
      "47/47 [==============================] - 2s 1ms/step - loss: 0.2295 - accuracy: 0.9202\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=16__optimizer=adam__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_114\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_114 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_11  (None, 64)               0         \n",
      " 4 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_114 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_228 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_229 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 5s 8ms/step - loss: 0.9731 - accuracy: 0.6900 - val_loss: 0.9065 - val_accuracy: 0.7407\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 4.8046 - accuracy: 0.7768 - val_loss: 8.5787 - val_accuracy: 0.7580\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 6.9706 - accuracy: 0.8160 - val_loss: 31.0401 - val_accuracy: 0.7434\n",
      "47/47 [==============================] - 2s 1ms/step - loss: 27.0857 - accuracy: 0.7686\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_115\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_115 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_11  (None, 64)               0         \n",
      " 5 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_115 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_230 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_231 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=16__optimizer=adam__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 5s 9ms/step - loss: 1.1187 - accuracy: 0.6845 - val_loss: 1.5359 - val_accuracy: 0.6396\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 4.4091 - accuracy: 0.7717 - val_loss: 10.6918 - val_accuracy: 0.7354\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 5.7770 - accuracy: 0.8178 - val_loss: 13.2579 - val_accuracy: 0.7660\n",
      "47/47 [==============================] - 2s 2ms/step - loss: 12.9783 - accuracy: 0.7832\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=16__optimizer=adam__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_116\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_116 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_11  (None, 64)               0         \n",
      " 6 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_116 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_232 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_233 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 6s 9ms/step - loss: 0.9618 - accuracy: 0.6921 - val_loss: 0.7736 - val_accuracy: 0.7806\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 4.9469 - accuracy: 0.7808 - val_loss: 4.0660 - val_accuracy: 0.8205\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 6.0802 - accuracy: 0.8311 - val_loss: 8.3170 - val_accuracy: 0.7766\n",
      "47/47 [==============================] - 2s 1ms/step - loss: 7.4519 - accuracy: 0.7726\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_117\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_117 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_11  (None, 64)               0         \n",
      " 7 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_117 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_234 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_235 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=16__optimizer=adam__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 5s 8ms/step - loss: 1.0353 - accuracy: 0.6819 - val_loss: 1.4303 - val_accuracy: 0.7686\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 4.2748 - accuracy: 0.7753 - val_loss: 8.0899 - val_accuracy: 0.7527\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 6.8461 - accuracy: 0.8206 - val_loss: 13.8699 - val_accuracy: 0.8191\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 15.1732 - accuracy: 0.8271\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=16__optimizer=adam__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_118\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_118 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_11  (None, 64)               0         \n",
      " 8 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_118 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_236 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_237 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 5s 8ms/step - loss: 0.9947 - accuracy: 0.6896 - val_loss: 0.8963 - val_accuracy: 0.7141\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 4.6168 - accuracy: 0.7658 - val_loss: 4.8819 - val_accuracy: 0.7447\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 4.2263 - accuracy: 0.8280 - val_loss: 10.3631 - val_accuracy: 0.7380\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 9.2056 - accuracy: 0.7434\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_119\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_119 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_11  (None, 64)               0         \n",
      " 9 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_119 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_238 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_239 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=16__optimizer=adam__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 5s 7ms/step - loss: 1.0603 - accuracy: 0.6857 - val_loss: 1.2319 - val_accuracy: 0.6755\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 6.6366 - accuracy: 0.7683 - val_loss: 10.2250 - val_accuracy: 0.8245\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 7.3212 - accuracy: 0.8150 - val_loss: 4.5037 - val_accuracy: 0.8032\n",
      "47/47 [==============================] - 1s 1ms/step - loss: 3.8158 - accuracy: 0.8191\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=16__optimizer=adam__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_120\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_120 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_12  (None, 64)               0         \n",
      " 0 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_120 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_240 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_241 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 11ms/step - loss: 0.5758 - accuracy: 0.6666 - val_loss: 0.3998 - val_accuracy: 0.8288\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 0.3749 - accuracy: 0.8391 - val_loss: 0.3106 - val_accuracy: 0.8777\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 0.3027 - accuracy: 0.8758 - val_loss: 0.2619 - val_accuracy: 0.9035\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.2902 - accuracy: 0.8940\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_121\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_121 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_12  (None, 64)               0         \n",
      " 1 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_121 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_242 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_243 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=32__optimizer=adam__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 11ms/step - loss: 0.5726 - accuracy: 0.6984 - val_loss: 0.4047 - val_accuracy: 0.8329\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3733 - accuracy: 0.8406 - val_loss: 0.3346 - val_accuracy: 0.8641\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.2992 - accuracy: 0.8831 - val_loss: 0.3031 - val_accuracy: 0.8832\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.2602 - accuracy: 0.8913\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=32__optimizer=adam__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_122\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_122 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_12  (None, 64)               0         \n",
      " 2 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_122 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_244 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_245 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 11ms/step - loss: 0.5779 - accuracy: 0.6732 - val_loss: 0.3948 - val_accuracy: 0.8356\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3733 - accuracy: 0.8363 - val_loss: 0.3213 - val_accuracy: 0.8573\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.2999 - accuracy: 0.8765 - val_loss: 0.2820 - val_accuracy: 0.8845\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.3036 - accuracy: 0.8845\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_123\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_123 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_12  (None, 64)               0         \n",
      " 3 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_123 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_246 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_247 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=32__optimizer=adam__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 11ms/step - loss: 0.5879 - accuracy: 0.6882 - val_loss: 0.4015 - val_accuracy: 0.8342\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3818 - accuracy: 0.8434 - val_loss: 0.3305 - val_accuracy: 0.8764\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3066 - accuracy: 0.8786 - val_loss: 0.2936 - val_accuracy: 0.8872\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.3127 - accuracy: 0.8804\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=32__optimizer=adam__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_124\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_124 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_12  (None, 64)               0         \n",
      " 4 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_124 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_248 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_249 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 11ms/step - loss: 0.5823 - accuracy: 0.6674 - val_loss: 0.3950 - val_accuracy: 0.8424\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3748 - accuracy: 0.8362 - val_loss: 0.3170 - val_accuracy: 0.8736\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 0.3013 - accuracy: 0.8803 - val_loss: 0.2748 - val_accuracy: 0.8995\n",
      "23/23 [==============================] - 1s 2ms/step - loss: 0.2975 - accuracy: 0.8927\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_125\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_125 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_12  (None, 64)               0         \n",
      " 5 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_125 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_250 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_251 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=32__optimizer=adam__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 11ms/step - loss: 0.5810 - accuracy: 0.6952 - val_loss: 0.4032 - val_accuracy: 0.8465\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 0.3846 - accuracy: 0.8383 - val_loss: 0.3210 - val_accuracy: 0.8832\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 0.3130 - accuracy: 0.8729 - val_loss: 0.2724 - val_accuracy: 0.9008\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.3040 - accuracy: 0.8764\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=32__optimizer=adam__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_126\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_126 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_12  (None, 64)               0         \n",
      " 6 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_126 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_252 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_253 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 11ms/step - loss: 0.6318 - accuracy: 0.7252 - val_loss: 0.4031 - val_accuracy: 0.8478\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 2.1055 - accuracy: 0.8151 - val_loss: 3.3467 - val_accuracy: 0.8315\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 3.9483 - accuracy: 0.8161 - val_loss: 5.0427 - val_accuracy: 0.7432\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 6.0035 - accuracy: 0.7310\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_127\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_127 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_12  (None, 64)               0         \n",
      " 7 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_127 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_254 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_255 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=32__optimizer=adam__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 11ms/step - loss: 0.6170 - accuracy: 0.7344 - val_loss: 0.7008 - val_accuracy: 0.7174\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 1.7878 - accuracy: 0.8036 - val_loss: 4.8347 - val_accuracy: 0.7486\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 3.3783 - accuracy: 0.8230 - val_loss: 3.6926 - val_accuracy: 0.8329\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 4.5852 - accuracy: 0.7962\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=32__optimizer=adam__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_128\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_128 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_12  (None, 64)               0         \n",
      " 8 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_128 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_256 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_257 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 12ms/step - loss: 0.6384 - accuracy: 0.7137 - val_loss: 0.5076 - val_accuracy: 0.7908\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 1.8424 - accuracy: 0.8041 - val_loss: 3.1025 - val_accuracy: 0.6807\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 2.8976 - accuracy: 0.8342 - val_loss: 4.2496 - val_accuracy: 0.7935\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 3.3256 - accuracy: 0.8084\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_129\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_129 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_12  (None, 64)               0         \n",
      " 9 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_129 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_258 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_259 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=32__optimizer=adam__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 12ms/step - loss: 0.6790 - accuracy: 0.7146 - val_loss: 0.4837 - val_accuracy: 0.7405\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 2.0410 - accuracy: 0.7993 - val_loss: 6.9154 - val_accuracy: 0.7663\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 4.2828 - accuracy: 0.8084 - val_loss: 8.5537 - val_accuracy: 0.7283\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 8.6112 - accuracy: 0.7174\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=32__optimizer=adam__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_130\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_130 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_13  (None, 64)               0         \n",
      " 0 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_130 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_260 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_261 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 12ms/step - loss: 0.6102 - accuracy: 0.7357 - val_loss: 0.7606 - val_accuracy: 0.6984\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 2.1342 - accuracy: 0.8036 - val_loss: 2.9541 - val_accuracy: 0.7446\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 2.4963 - accuracy: 0.8372 - val_loss: 4.9052 - val_accuracy: 0.7446\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 5.7030 - accuracy: 0.7160\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_131\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_131 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_13  (None, 64)               0         \n",
      " 1 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_131 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_262 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_263 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=32__optimizer=adam__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 11ms/step - loss: 0.6262 - accuracy: 0.7161 - val_loss: 0.4461 - val_accuracy: 0.8329\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 1.6653 - accuracy: 0.8048 - val_loss: 2.6791 - val_accuracy: 0.7459\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 2.6252 - accuracy: 0.8220 - val_loss: 3.8367 - val_accuracy: 0.8016\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 3.3049 - accuracy: 0.8084\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=32__optimizer=adam__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_132\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_132 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_13  (None, 64)               0         \n",
      " 2 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_132 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_264 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_265 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 3s 19ms/step - loss: 0.6453 - accuracy: 0.6020 - val_loss: 0.5452 - val_accuracy: 0.7230\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.4212 - accuracy: 0.8141 - val_loss: 0.3937 - val_accuracy: 0.8366\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.3311 - accuracy: 0.8646 - val_loss: 0.3477 - val_accuracy: 0.8622\n",
      "11/11 [==============================] - 1s 1ms/step - loss: 0.2745 - accuracy: 0.8935\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_133\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_133 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_13  (None, 64)               0         \n",
      " 3 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_133 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_266 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_267 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=64__optimizer=adam__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 19ms/step - loss: 0.6351 - accuracy: 0.6357 - val_loss: 0.5005 - val_accuracy: 0.7955\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.4175 - accuracy: 0.8232 - val_loss: 0.3713 - val_accuracy: 0.8381\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.3287 - accuracy: 0.8640 - val_loss: 0.3326 - val_accuracy: 0.8594\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.3338 - accuracy: 0.8622\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=64__optimizer=adam__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_134\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_134 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_13  (None, 64)               0         \n",
      " 4 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_134 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_268 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_269 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 3s 19ms/step - loss: 0.6451 - accuracy: 0.5962 - val_loss: 0.5046 - val_accuracy: 0.7699\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 0.4215 - accuracy: 0.8123 - val_loss: 0.3231 - val_accuracy: 0.8693\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.3301 - accuracy: 0.8572 - val_loss: 0.2738 - val_accuracy: 0.8892\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.3067 - accuracy: 0.8835\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_135\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_135 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_13  (None, 64)               0         \n",
      " 5 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_135 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_270 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_271 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=64__optimizer=adam__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 3s 18ms/step - loss: 0.6330 - accuracy: 0.6495 - val_loss: 0.4808 - val_accuracy: 0.8054\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.4078 - accuracy: 0.8293 - val_loss: 0.3428 - val_accuracy: 0.8608\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 0.3189 - accuracy: 0.8706 - val_loss: 0.2982 - val_accuracy: 0.8793\n",
      "11/11 [==============================] - 1s 1ms/step - loss: 0.2871 - accuracy: 0.8906\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=64__optimizer=adam__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_136\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_136 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_13  (None, 64)               0         \n",
      " 6 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_136 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_272 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_273 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 3s 18ms/step - loss: 0.6480 - accuracy: 0.5972 - val_loss: 0.5332 - val_accuracy: 0.7401\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 0.4261 - accuracy: 0.8100 - val_loss: 0.3692 - val_accuracy: 0.8537\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 0.3288 - accuracy: 0.8628 - val_loss: 0.3167 - val_accuracy: 0.8778\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.3295 - accuracy: 0.8693\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_137\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_137 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_13  (None, 64)               0         \n",
      " 7 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_137 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_274 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_275 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=64__optimizer=adam__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 21ms/step - loss: 0.6382 - accuracy: 0.6375 - val_loss: 0.4994 - val_accuracy: 0.8082\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.4171 - accuracy: 0.8202 - val_loss: 0.3754 - val_accuracy: 0.8423\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.3338 - accuracy: 0.8632 - val_loss: 0.3219 - val_accuracy: 0.8722\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.2929 - accuracy: 0.8878\n",
      "run=0__lr=0.001__hidden_unit=64__batch_size=64__optimizer=adam__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_138\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_138 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_13  (None, 64)               0         \n",
      " 8 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_138 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_276 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_277 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 20ms/step - loss: 0.5332 - accuracy: 0.7465 - val_loss: 0.3609 - val_accuracy: 0.8551\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.6926 - accuracy: 0.8470 - val_loss: 1.1411 - val_accuracy: 0.8295\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.8393 - accuracy: 0.8600 - val_loss: 2.0885 - val_accuracy: 0.7912\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 2.0318 - accuracy: 0.7940\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_139\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_139 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_13  (None, 64)               0         \n",
      " 9 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_139 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_278 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_279 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=64__optimizer=adam__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 23ms/step - loss: 0.5664 - accuracy: 0.7273 - val_loss: 0.3614 - val_accuracy: 0.8679\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.5496 - accuracy: 0.8541 - val_loss: 1.3831 - val_accuracy: 0.8111\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 1.4891 - accuracy: 0.8457 - val_loss: 2.3831 - val_accuracy: 0.8196\n",
      "11/11 [==============================] - 2s 2ms/step - loss: 3.2662 - accuracy: 0.7983\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=64__optimizer=adam__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_140\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_140 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_14  (None, 64)               0         \n",
      " 0 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_140 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_280 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_281 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 25ms/step - loss: 0.5426 - accuracy: 0.7507 - val_loss: 0.4211 - val_accuracy: 0.8295\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.8993 - accuracy: 0.8186 - val_loss: 1.7562 - val_accuracy: 0.7869\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.9891 - accuracy: 0.8484 - val_loss: 0.9837 - val_accuracy: 0.8068\n",
      "11/11 [==============================] - 2s 2ms/step - loss: 0.9945 - accuracy: 0.8111\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_141\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_141 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_14  (None, 64)               0         \n",
      " 1 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_141 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_282 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_283 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=64__optimizer=adam__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 24ms/step - loss: 0.5393 - accuracy: 0.7553 - val_loss: 0.3830 - val_accuracy: 0.8168\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.7936 - accuracy: 0.8285 - val_loss: 0.9160 - val_accuracy: 0.8267\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.9476 - accuracy: 0.8554 - val_loss: 2.4116 - val_accuracy: 0.8310\n",
      "11/11 [==============================] - 2s 2ms/step - loss: 2.3365 - accuracy: 0.8153\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=64__optimizer=adam__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_142\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_142 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_14  (None, 64)               0         \n",
      " 2 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_142 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_284 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_285 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 23ms/step - loss: 0.5199 - accuracy: 0.7480 - val_loss: 0.3207 - val_accuracy: 0.8736\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.5716 - accuracy: 0.8548 - val_loss: 0.6158 - val_accuracy: 0.7727\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.9312 - accuracy: 0.8661 - val_loss: 1.5763 - val_accuracy: 0.8338\n",
      "11/11 [==============================] - 2s 2ms/step - loss: 1.5088 - accuracy: 0.8267\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_143\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_143 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_14  (None, 64)               0         \n",
      " 3 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_143 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_286 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_287 (Dense)           (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,354\n",
      "Trainable params: 324,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=64__optimizer=adam__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 24ms/step - loss: 0.5473 - accuracy: 0.7464 - val_loss: 0.4026 - val_accuracy: 0.8480\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.9206 - accuracy: 0.8148 - val_loss: 1.0646 - val_accuracy: 0.7486\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 1.1359 - accuracy: 0.8248 - val_loss: 2.1472 - val_accuracy: 0.6960\n",
      "11/11 [==============================] - 2s 2ms/step - loss: 1.6371 - accuracy: 0.7315\n",
      "run=0__lr=0.1__hidden_unit=64__batch_size=64__optimizer=adam__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_144\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_144 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_14  (None, 64)               0         \n",
      " 4 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_144 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_288 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_289 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 6s 10ms/step - loss: 0.5261 - accuracy: 0.7265 - val_loss: 0.3649 - val_accuracy: 0.8457\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 0.3548 - accuracy: 0.8510 - val_loss: 0.2998 - val_accuracy: 0.8830\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 0.2836 - accuracy: 0.8887 - val_loss: 0.2698 - val_accuracy: 0.9029\n",
      "47/47 [==============================] - 2s 1ms/step - loss: 0.2793 - accuracy: 0.8896\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_145\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_145 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_14  (None, 64)               0         \n",
      " 5 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_145 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_290 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_291 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=16__optimizer=adam__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 6s 9ms/step - loss: 0.5293 - accuracy: 0.7452 - val_loss: 0.3786 - val_accuracy: 0.8524\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 0.3596 - accuracy: 0.8480 - val_loss: 0.3141 - val_accuracy: 0.8750\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 0.2895 - accuracy: 0.8859 - val_loss: 0.2801 - val_accuracy: 0.8989\n",
      "47/47 [==============================] - 2s 1ms/step - loss: 0.2694 - accuracy: 0.9016\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=16__optimizer=adam__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_146\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_146 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_14  (None, 64)               0         \n",
      " 6 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_146 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_292 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_293 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 6s 9ms/step - loss: 0.5201 - accuracy: 0.7240 - val_loss: 0.3825 - val_accuracy: 0.8418\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 0.3469 - accuracy: 0.8551 - val_loss: 0.3276 - val_accuracy: 0.8750\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 0.2802 - accuracy: 0.8877 - val_loss: 0.3022 - val_accuracy: 0.8896\n",
      "47/47 [==============================] - 2s 1ms/step - loss: 0.2943 - accuracy: 0.8989\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_147\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_147 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_14  (None, 64)               0         \n",
      " 7 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_147 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_294 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_295 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=16__optimizer=adam__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 6s 10ms/step - loss: 0.5261 - accuracy: 0.7336 - val_loss: 0.3534 - val_accuracy: 0.8710\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 0.3561 - accuracy: 0.8544 - val_loss: 0.2860 - val_accuracy: 0.8963\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 0.2893 - accuracy: 0.8885 - val_loss: 0.2562 - val_accuracy: 0.9096\n",
      "47/47 [==============================] - 2s 1ms/step - loss: 0.2578 - accuracy: 0.9069\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=16__optimizer=adam__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_148\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_148 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_14  (None, 64)               0         \n",
      " 8 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_148 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_296 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_297 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 6s 9ms/step - loss: 0.5249 - accuracy: 0.7189 - val_loss: 0.4052 - val_accuracy: 0.8271\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 0.3492 - accuracy: 0.8507 - val_loss: 0.3451 - val_accuracy: 0.8657\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 0.2826 - accuracy: 0.8860 - val_loss: 0.3115 - val_accuracy: 0.8790\n",
      "47/47 [==============================] - 2s 1ms/step - loss: 0.3258 - accuracy: 0.8697\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_149\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_149 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_14  (None, 64)               0         \n",
      " 9 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_149 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_298 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_299 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=16__optimizer=adam__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 6s 9ms/step - loss: 0.5260 - accuracy: 0.7308 - val_loss: 0.3618 - val_accuracy: 0.8577\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 0.3568 - accuracy: 0.8493 - val_loss: 0.2932 - val_accuracy: 0.8949\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 0.2849 - accuracy: 0.8870 - val_loss: 0.2552 - val_accuracy: 0.9056\n",
      "47/47 [==============================] - 2s 1ms/step - loss: 0.2422 - accuracy: 0.9189\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=16__optimizer=adam__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_150\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_150 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_15  (None, 64)               0         \n",
      " 0 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_150 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_300 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_301 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 6s 10ms/step - loss: 1.8338 - accuracy: 0.6602 - val_loss: 2.6270 - val_accuracy: 0.5705\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 12.9087 - accuracy: 0.7571 - val_loss: 14.6099 - val_accuracy: 0.6875\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 12.1185 - accuracy: 0.8189 - val_loss: 17.5966 - val_accuracy: 0.8231\n",
      "47/47 [==============================] - 2s 2ms/step - loss: 19.1895 - accuracy: 0.8059\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_151\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_151 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_15  (None, 64)               0         \n",
      " 1 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_151 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_302 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_303 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=16__optimizer=adam__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 6s 10ms/step - loss: 1.8762 - accuracy: 0.6715 - val_loss: 3.3413 - val_accuracy: 0.5545\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 6ms/step - loss: 11.4532 - accuracy: 0.7569 - val_loss: 10.6875 - val_accuracy: 0.7500\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 13.0278 - accuracy: 0.8234 - val_loss: 11.7054 - val_accuracy: 0.8497\n",
      "47/47 [==============================] - 2s 2ms/step - loss: 17.3940 - accuracy: 0.8338\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=16__optimizer=adam__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_152\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_152 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_15  (None, 64)               0         \n",
      " 2 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_152 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_304 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_305 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 6s 10ms/step - loss: 2.0492 - accuracy: 0.6669 - val_loss: 2.0960 - val_accuracy: 0.7979\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 9.0350 - accuracy: 0.7689 - val_loss: 11.0195 - val_accuracy: 0.7380\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 9.7383 - accuracy: 0.8336 - val_loss: 21.3343 - val_accuracy: 0.7540\n",
      "47/47 [==============================] - 2s 2ms/step - loss: 27.8402 - accuracy: 0.7261\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_153\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_153 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_15  (None, 64)               0         \n",
      " 3 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_153 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_306 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_307 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=16__optimizer=adam__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 7s 10ms/step - loss: 1.7280 - accuracy: 0.6719 - val_loss: 2.0662 - val_accuracy: 0.8245\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 10.7419 - accuracy: 0.7689 - val_loss: 19.3793 - val_accuracy: 0.6024\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 13.6185 - accuracy: 0.8183 - val_loss: 15.0127 - val_accuracy: 0.7500\n",
      "47/47 [==============================] - 2s 2ms/step - loss: 15.2775 - accuracy: 0.7434\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=16__optimizer=adam__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_154\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_154 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_15  (None, 64)               0         \n",
      " 4 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_154 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_308 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_309 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 7s 10ms/step - loss: 1.5916 - accuracy: 0.6791 - val_loss: 2.1672 - val_accuracy: 0.7088\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 6ms/step - loss: 9.3440 - accuracy: 0.7658 - val_loss: 8.6856 - val_accuracy: 0.7686\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 8.8167 - accuracy: 0.8280 - val_loss: 18.3108 - val_accuracy: 0.7673\n",
      "47/47 [==============================] - 2s 1ms/step - loss: 24.9757 - accuracy: 0.7566\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=16__optimizer=adam__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_155\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_155 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_15  (None, 64)               0         \n",
      " 5 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_155 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_310 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_311 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=16__optimizer=adam__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 6s 9ms/step - loss: 1.8511 - accuracy: 0.6694 - val_loss: 2.7974 - val_accuracy: 0.7114\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 7.3221 - accuracy: 0.7826 - val_loss: 14.3389 - val_accuracy: 0.7473\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 14.2418 - accuracy: 0.8299 - val_loss: 22.5085 - val_accuracy: 0.8231\n",
      "47/47 [==============================] - 2s 1ms/step - loss: 20.7811 - accuracy: 0.8005\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=16__optimizer=adam__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_156\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_156 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_15  (None, 64)               0         \n",
      " 6 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_156 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_312 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_313 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 5s 14ms/step - loss: 0.5601 - accuracy: 0.6854 - val_loss: 0.3885 - val_accuracy: 0.8302\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 0.3685 - accuracy: 0.8410 - val_loss: 0.3060 - val_accuracy: 0.8872\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 0.2974 - accuracy: 0.8791 - val_loss: 0.2662 - val_accuracy: 0.9035\n",
      "23/23 [==============================] - 2s 1ms/step - loss: 0.2978 - accuracy: 0.8859\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_157\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_157 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_15  (None, 64)               0         \n",
      " 7 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_157 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_314 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_315 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=32__optimizer=adam__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 5s 13ms/step - loss: 0.5585 - accuracy: 0.7048 - val_loss: 0.3644 - val_accuracy: 0.8614\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 0.3662 - accuracy: 0.8487 - val_loss: 0.2865 - val_accuracy: 0.8927\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 0.2940 - accuracy: 0.8849 - val_loss: 0.2469 - val_accuracy: 0.9117\n",
      "23/23 [==============================] - 2s 2ms/step - loss: 0.2953 - accuracy: 0.8845\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=32__optimizer=adam__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_158\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_158 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_15  (None, 64)               0         \n",
      " 8 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_158 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_316 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_317 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 12ms/step - loss: 0.5666 - accuracy: 0.6860 - val_loss: 0.3923 - val_accuracy: 0.8410\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 0.3673 - accuracy: 0.8433 - val_loss: 0.3133 - val_accuracy: 0.8723\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 0.2961 - accuracy: 0.8806 - val_loss: 0.2702 - val_accuracy: 0.8995\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.2888 - accuracy: 0.8927\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_159\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_159 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_15  (None, 64)               0         \n",
      " 9 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_159 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_318 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_319 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=32__optimizer=adam__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 13ms/step - loss: 0.5627 - accuracy: 0.7012 - val_loss: 0.3835 - val_accuracy: 0.8519\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 0.3645 - accuracy: 0.8474 - val_loss: 0.3200 - val_accuracy: 0.8709\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 0.2932 - accuracy: 0.8859 - val_loss: 0.2870 - val_accuracy: 0.8886\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.3004 - accuracy: 0.8899\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=32__optimizer=adam__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_160\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_160 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_16  (None, 64)               0         \n",
      " 0 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_160 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_320 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_321 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 12ms/step - loss: 0.5701 - accuracy: 0.6857 - val_loss: 0.3678 - val_accuracy: 0.8546\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 0.3691 - accuracy: 0.8406 - val_loss: 0.2828 - val_accuracy: 0.8899\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 0.2971 - accuracy: 0.8785 - val_loss: 0.2327 - val_accuracy: 0.9117\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.2478 - accuracy: 0.9035\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_161\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_161 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_16  (None, 64)               0         \n",
      " 1 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_161 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_322 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_323 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=32__optimizer=adam__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 12ms/step - loss: 0.5609 - accuracy: 0.7012 - val_loss: 0.3933 - val_accuracy: 0.8302\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 0.3723 - accuracy: 0.8421 - val_loss: 0.3259 - val_accuracy: 0.8641\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 0.3020 - accuracy: 0.8796 - val_loss: 0.2847 - val_accuracy: 0.8927\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.3044 - accuracy: 0.8913\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=32__optimizer=adam__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_162\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_162 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_16  (None, 64)               0         \n",
      " 2 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_162 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_324 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_325 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 5s 13ms/step - loss: 0.7650 - accuracy: 0.6967 - val_loss: 0.6061 - val_accuracy: 0.7867\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 4.0055 - accuracy: 0.7877 - val_loss: 5.5803 - val_accuracy: 0.7704\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 6.1140 - accuracy: 0.8194 - val_loss: 11.4037 - val_accuracy: 0.8016\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 13.4730 - accuracy: 0.8057\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_163\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_163 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_16  (None, 64)               0         \n",
      " 3 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_163 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_326 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_327 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=32__optimizer=adam__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 12ms/step - loss: 0.6990 - accuracy: 0.7120 - val_loss: 0.7360 - val_accuracy: 0.7228\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 3.5302 - accuracy: 0.7887 - val_loss: 9.4174 - val_accuracy: 0.6535\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 6.1310 - accuracy: 0.8153 - val_loss: 12.8182 - val_accuracy: 0.6495\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 11.5398 - accuracy: 0.6630\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=32__optimizer=adam__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_164\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_164 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_16  (None, 64)               0         \n",
      " 4 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_164 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_328 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_329 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 4s 12ms/step - loss: 0.8148 - accuracy: 0.7061 - val_loss: 1.2235 - val_accuracy: 0.7446\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 5.8929 - accuracy: 0.7699 - val_loss: 10.2631 - val_accuracy: 0.8247\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 8.0071 - accuracy: 0.8194 - val_loss: 12.0073 - val_accuracy: 0.8342\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 16.3494 - accuracy: 0.8234\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_165\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_165 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_16  (None, 64)               0         \n",
      " 5 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_165 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_330 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_331 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=32__optimizer=adam__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 5s 15ms/step - loss: 0.7874 - accuracy: 0.6969 - val_loss: 0.9710 - val_accuracy: 0.7731\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 3.1691 - accuracy: 0.7747 - val_loss: 3.5830 - val_accuracy: 0.7935\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 3.9818 - accuracy: 0.8387 - val_loss: 8.4160 - val_accuracy: 0.8139\n",
      "23/23 [==============================] - 2s 2ms/step - loss: 9.6981 - accuracy: 0.8030\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=32__optimizer=adam__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_166\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_166 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_16  (None, 64)               0         \n",
      " 6 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_166 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_332 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_333 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 5s 15ms/step - loss: 0.6956 - accuracy: 0.7127 - val_loss: 0.8325 - val_accuracy: 0.8084\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 4.1382 - accuracy: 0.7878 - val_loss: 9.6602 - val_accuracy: 0.7554\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 7.4123 - accuracy: 0.8118 - val_loss: 10.7575 - val_accuracy: 0.8247\n",
      "23/23 [==============================] - 2s 1ms/step - loss: 11.4787 - accuracy: 0.7921\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=32__optimizer=adam__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_167\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_167 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_16  (None, 64)               0         \n",
      " 7 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_167 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_334 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_335 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=32__optimizer=adam__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - 5s 14ms/step - loss: 0.7506 - accuracy: 0.7035 - val_loss: 0.8311 - val_accuracy: 0.8274\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 3.7931 - accuracy: 0.7727 - val_loss: 7.1700 - val_accuracy: 0.7663\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 5.1076 - accuracy: 0.8248 - val_loss: 8.1210 - val_accuracy: 0.7486\n",
      "23/23 [==============================] - 2s 2ms/step - loss: 8.5293 - accuracy: 0.7201\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=32__optimizer=adam__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_168\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_168 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_16  (None, 64)               0         \n",
      " 8 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_168 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_336 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_337 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 5s 32ms/step - loss: 0.6266 - accuracy: 0.6215 - val_loss: 0.4598 - val_accuracy: 0.8111\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.3931 - accuracy: 0.8303 - val_loss: 0.3429 - val_accuracy: 0.8608\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.3077 - accuracy: 0.8763 - val_loss: 0.3019 - val_accuracy: 0.8722\n",
      "11/11 [==============================] - 2s 3ms/step - loss: 0.2928 - accuracy: 0.8878\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_169\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_169 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_16  (None, 64)               0         \n",
      " 9 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_169 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_338 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_339 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=64__optimizer=adam__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 4s 24ms/step - loss: 0.6182 - accuracy: 0.6595 - val_loss: 0.4304 - val_accuracy: 0.8253\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.4018 - accuracy: 0.8268 - val_loss: 0.3327 - val_accuracy: 0.8594\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.3180 - accuracy: 0.8732 - val_loss: 0.2942 - val_accuracy: 0.8736\n",
      "11/11 [==============================] - 2s 2ms/step - loss: 0.2796 - accuracy: 0.8821\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=64__optimizer=adam__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_170\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_170 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_17  (None, 64)               0         \n",
      " 0 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_170 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_340 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_341 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 5s 24ms/step - loss: 0.6326 - accuracy: 0.6174 - val_loss: 0.4713 - val_accuracy: 0.7884\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.4000 - accuracy: 0.8268 - val_loss: 0.3327 - val_accuracy: 0.8665\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.3142 - accuracy: 0.8732 - val_loss: 0.2838 - val_accuracy: 0.8920\n",
      "11/11 [==============================] - 2s 2ms/step - loss: 0.2999 - accuracy: 0.8878\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_171\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_171 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_17  (None, 64)               0         \n",
      " 1 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_171 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_342 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_343 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=64__optimizer=adam__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 5s 25ms/step - loss: 0.6093 - accuracy: 0.6582 - val_loss: 0.4283 - val_accuracy: 0.8281\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.3884 - accuracy: 0.8344 - val_loss: 0.3165 - val_accuracy: 0.8821\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.3065 - accuracy: 0.8735 - val_loss: 0.2739 - val_accuracy: 0.9006\n",
      "11/11 [==============================] - 2s 2ms/step - loss: 0.2879 - accuracy: 0.8949\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=64__optimizer=adam__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_172\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_172 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_17  (None, 64)               0         \n",
      " 2 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_172 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_344 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_345 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 6s 33ms/step - loss: 0.6355 - accuracy: 0.6143 - val_loss: 0.4549 - val_accuracy: 0.7997\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.4007 - accuracy: 0.8270 - val_loss: 0.3353 - val_accuracy: 0.8580\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.3149 - accuracy: 0.8714 - val_loss: 0.2879 - val_accuracy: 0.8906\n",
      "11/11 [==============================] - 2s 2ms/step - loss: 0.3030 - accuracy: 0.8693\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_173\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_173 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_17  (None, 64)               0         \n",
      " 3 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_173 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_346 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_347 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=64__optimizer=adam__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 5s 28ms/step - loss: 0.6230 - accuracy: 0.6475 - val_loss: 0.4388 - val_accuracy: 0.8324\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.4006 - accuracy: 0.8317 - val_loss: 0.3290 - val_accuracy: 0.8807\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 0.3149 - accuracy: 0.8720 - val_loss: 0.2853 - val_accuracy: 0.8963\n",
      "11/11 [==============================] - 2s 2ms/step - loss: 0.2622 - accuracy: 0.9020\n",
      "run=0__lr=0.001__hidden_unit=128__batch_size=64__optimizer=adam__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_174\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_174 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_17  (None, 64)               0         \n",
      " 4 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_174 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_348 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_349 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 5s 27ms/step - loss: 0.5823 - accuracy: 0.7252 - val_loss: 0.4001 - val_accuracy: 0.8409\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 1.2672 - accuracy: 0.8046 - val_loss: 1.3898 - val_accuracy: 0.8068\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 1.6648 - accuracy: 0.8148 - val_loss: 2.3411 - val_accuracy: 0.7869\n",
      "11/11 [==============================] - 2s 2ms/step - loss: 1.7776 - accuracy: 0.8026\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_175\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_175 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_17  (None, 64)               0         \n",
      " 5 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_175 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_350 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_351 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=64__optimizer=adam__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 5s 29ms/step - loss: 0.5724 - accuracy: 0.7309 - val_loss: 0.3189 - val_accuracy: 0.8821\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 1.7197 - accuracy: 0.8071 - val_loss: 2.9645 - val_accuracy: 0.5284\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 2.1104 - accuracy: 0.8137 - val_loss: 2.2837 - val_accuracy: 0.8366\n",
      "11/11 [==============================] - 2s 3ms/step - loss: 2.9632 - accuracy: 0.8253\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=64__optimizer=adam__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_176\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_176 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_17  (None, 64)               0         \n",
      " 6 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_176 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_352 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_353 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 6s 31ms/step - loss: 0.6128 - accuracy: 0.7192 - val_loss: 0.4306 - val_accuracy: 0.8352\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 0.9589 - accuracy: 0.8258 - val_loss: 3.0071 - val_accuracy: 0.7571\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 2.9457 - accuracy: 0.8207 - val_loss: 5.4934 - val_accuracy: 0.7202\n",
      "11/11 [==============================] - 2s 3ms/step - loss: 5.8814 - accuracy: 0.6960\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_177\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_177 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_17  (None, 64)               0         \n",
      " 7 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_177 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_354 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_355 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=64__optimizer=adam__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 6s 32ms/step - loss: 0.5809 - accuracy: 0.7391 - val_loss: 0.3679 - val_accuracy: 0.8381\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 1.1206 - accuracy: 0.8155 - val_loss: 2.8054 - val_accuracy: 0.7585\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 2.5167 - accuracy: 0.8174 - val_loss: 5.9625 - val_accuracy: 0.7358\n",
      "11/11 [==============================] - 2s 2ms/step - loss: 5.6065 - accuracy: 0.7656\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=64__optimizer=adam__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_178\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_178 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_17  (None, 64)               0         \n",
      " 8 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_178 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_356 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_357 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 6s 29ms/step - loss: 0.5755 - accuracy: 0.7294 - val_loss: 0.3781 - val_accuracy: 0.8423\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 8ms/step - loss: 1.4559 - accuracy: 0.8188 - val_loss: 1.8889 - val_accuracy: 0.7628\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 2.1092 - accuracy: 0.8234 - val_loss: 3.8838 - val_accuracy: 0.7188\n",
      "11/11 [==============================] - 2s 2ms/step - loss: 3.7905 - accuracy: 0.7188\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=64__optimizer=adam__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_179\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_179 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_17  (None, 64)               0         \n",
      " 9 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_179 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_358 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_359 (Dense)           (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 328,642\n",
      "Trainable params: 328,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=64__optimizer=adam__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "95/95 [==============================] - 5s 32ms/step - loss: 0.6229 - accuracy: 0.7158 - val_loss: 0.5590 - val_accuracy: 0.6932\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 1.2504 - accuracy: 0.7998 - val_loss: 1.2753 - val_accuracy: 0.8295\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 1s 7ms/step - loss: 2.0457 - accuracy: 0.8266 - val_loss: 2.7605 - val_accuracy: 0.7955\n",
      "11/11 [==============================] - 2s 3ms/step - loss: 2.5868 - accuracy: 0.7997\n",
      "run=0__lr=0.1__hidden_unit=128__batch_size=64__optimizer=adam__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_180\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_180 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_18  (None, 64)               0         \n",
      " 0 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_180 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_360 (Dense)           (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_361 (Dense)           (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=16__optimizer=adamw__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 6s 9ms/step - loss: 0.6261 - accuracy: 0.6396 - val_loss: 0.4911 - val_accuracy: 0.7992\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 0.4173 - accuracy: 0.8227 - val_loss: 0.4049 - val_accuracy: 0.8298\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 0.3517 - accuracy: 0.8571 - val_loss: 0.3930 - val_accuracy: 0.8364\n",
      "47/47 [==============================] - 2s 1ms/step - loss: 0.3379 - accuracy: 0.8750\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=16__optimizer=adamw__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_181\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_181 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_18  (None, 64)               0         \n",
      " 1 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_181 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_362 (Dense)           (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_363 (Dense)           (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=16__optimizer=adamw__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 6s 9ms/step - loss: 0.6157 - accuracy: 0.6905 - val_loss: 0.4522 - val_accuracy: 0.8298\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 0.4157 - accuracy: 0.8258 - val_loss: 0.3678 - val_accuracy: 0.8511\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 0.3517 - accuracy: 0.8610 - val_loss: 0.3540 - val_accuracy: 0.8604\n",
      "47/47 [==============================] - 2s 1ms/step - loss: 0.3477 - accuracy: 0.8644\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=16__optimizer=adamw__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_182\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_182 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_18  (None, 64)               0         \n",
      " 2 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_182 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_364 (Dense)           (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_365 (Dense)           (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=16__optimizer=adamw__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 6s 9ms/step - loss: 0.6232 - accuracy: 0.6377 - val_loss: 0.4485 - val_accuracy: 0.8112\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 4ms/step - loss: 0.4135 - accuracy: 0.8217 - val_loss: 0.3721 - val_accuracy: 0.8577\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 0.3523 - accuracy: 0.8554 - val_loss: 0.3585 - val_accuracy: 0.8630\n",
      "47/47 [==============================] - 2s 1ms/step - loss: 0.3460 - accuracy: 0.8551\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=16__optimizer=adamw__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_183\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_183 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_18  (None, 64)               0         \n",
      " 3 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_183 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_366 (Dense)           (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_367 (Dense)           (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=16__optimizer=adamw__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 6s 10ms/step - loss: 0.6044 - accuracy: 0.6905 - val_loss: 0.4460 - val_accuracy: 0.8271\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 0.4050 - accuracy: 0.8362 - val_loss: 0.3687 - val_accuracy: 0.8471\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 0.3421 - accuracy: 0.8674 - val_loss: 0.3550 - val_accuracy: 0.8497\n",
      "47/47 [==============================] - 2s 1ms/step - loss: 0.3533 - accuracy: 0.8590\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=16__optimizer=adamw__class_weights=none__dropout=0.2 completed.\n",
      "Model: \"sequential_184\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_184 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_18  (None, 64)               0         \n",
      " 4 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_184 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_368 (Dense)           (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_369 (Dense)           (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=16__optimizer=adamw__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 6s 10ms/step - loss: 0.6327 - accuracy: 0.6255 - val_loss: 0.4873 - val_accuracy: 0.7779\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 0.4194 - accuracy: 0.8161 - val_loss: 0.4131 - val_accuracy: 0.8032\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 0.3583 - accuracy: 0.8507 - val_loss: 0.3972 - val_accuracy: 0.8178\n",
      "47/47 [==============================] - 2s 1ms/step - loss: 0.4136 - accuracy: 0.8178\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=16__optimizer=adamw__class_weights=balanced__dropout=0.3 completed.\n",
      "Model: \"sequential_185\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_185 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_18  (None, 64)               0         \n",
      " 5 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_185 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_370 (Dense)           (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_371 (Dense)           (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=16__optimizer=adamw__class_weights=none__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 6s 10ms/step - loss: 0.6124 - accuracy: 0.6766 - val_loss: 0.4599 - val_accuracy: 0.8231\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 0.4133 - accuracy: 0.8324 - val_loss: 0.3768 - val_accuracy: 0.8444\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 0.3499 - accuracy: 0.8617 - val_loss: 0.3600 - val_accuracy: 0.8524\n",
      "47/47 [==============================] - 2s 2ms/step - loss: 0.3374 - accuracy: 0.8697\n",
      "run=0__lr=0.001__hidden_unit=8__batch_size=16__optimizer=adamw__class_weights=none__dropout=0.3 completed.\n",
      "Model: \"sequential_186\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_186 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_18  (None, 64)               0         \n",
      " 6 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_186 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_372 (Dense)           (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_373 (Dense)           (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=16__optimizer=adamw__class_weights=balanced__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 6s 10ms/step - loss: 0.5352 - accuracy: 0.7385 - val_loss: 0.3796 - val_accuracy: 0.8298\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 0.3603 - accuracy: 0.8533 - val_loss: 0.4424 - val_accuracy: 0.8324\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 0.2968 - accuracy: 0.8929 - val_loss: 0.3522 - val_accuracy: 0.8684\n",
      "47/47 [==============================] - 2s 2ms/step - loss: 0.3199 - accuracy: 0.8763\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=16__optimizer=adamw__class_weights=balanced__dropout=0.1 completed.\n",
      "Model: \"sequential_187\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_187 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_18  (None, 64)               0         \n",
      " 7 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_187 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_374 (Dense)           (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_375 (Dense)           (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=16__optimizer=adamw__class_weights=none__dropout=0.1 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 7s 13ms/step - loss: 0.5440 - accuracy: 0.7470 - val_loss: 0.3833 - val_accuracy: 0.8338\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 6ms/step - loss: 0.3750 - accuracy: 0.8518 - val_loss: 0.4356 - val_accuracy: 0.8418\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 6ms/step - loss: 0.2809 - accuracy: 0.9007 - val_loss: 0.3724 - val_accuracy: 0.8471\n",
      "47/47 [==============================] - 2s 1ms/step - loss: 0.3451 - accuracy: 0.8684\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=16__optimizer=adamw__class_weights=none__dropout=0.1 completed.\n",
      "Model: \"sequential_188\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_188 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_18  (None, 64)               0         \n",
      " 8 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_188 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_376 (Dense)           (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_377 (Dense)           (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=16__optimizer=adamw__class_weights=balanced__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "380/380 [==============================] - 7s 11ms/step - loss: 0.5492 - accuracy: 0.7382 - val_loss: 0.3692 - val_accuracy: 0.8537\n",
      "Epoch 2/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 0.3624 - accuracy: 0.8525 - val_loss: 0.4116 - val_accuracy: 0.8125\n",
      "Epoch 3/3\n",
      "380/380 [==============================] - 2s 5ms/step - loss: 0.2894 - accuracy: 0.8883 - val_loss: 0.2835 - val_accuracy: 0.8790\n",
      "47/47 [==============================] - 2s 2ms/step - loss: 0.2833 - accuracy: 0.8870\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=16__optimizer=adamw__class_weights=balanced__dropout=0.2 completed.\n",
      "Model: \"sequential_189\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_189 (Embedding)   (None, None, 64)          320064    \n",
      "                                                                 \n",
      " global_average_pooling1d_18  (None, 64)               0         \n",
      " 9 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dropout_189 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_378 (Dense)           (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_379 (Dense)           (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,602\n",
      "Trainable params: 320,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "run=0__lr=0.1__hidden_unit=8__batch_size=16__optimizer=adamw__class_weights=none__dropout=0.2 starting...\n",
      "Epoch 1/3\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.5373 - accuracy: 0.7480"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_826676/3424562064.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     24\u001B[0m                         \u001B[0;32mwith\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msummary\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcreate_file_writer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'{log_directory}{model.run_name}'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mas_default\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m                             \u001B[0mhp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhparams\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhparams\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 26\u001B[0;31m                             \u001B[0maccuracy\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprecision\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecall\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mf1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit_and_evaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlog_directory\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlog_directory\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     27\u001B[0m                             \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msummary\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mscalar\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"accuracy\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maccuracy\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstep\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m                             \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msummary\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mscalar\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"precision\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprecision\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstep\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/TUM Informatik/WS2122/Applied Deep Learning for NLP/KAGGLE_NLP_with_disaster_tweets/model/base_model.py\u001B[0m in \u001B[0;36mfit_and_evaluate\u001B[0;34m(self, log_directory)\u001B[0m\n\u001B[1;32m     81\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mfit_and_evaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlog_directory\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     82\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"{self.run_name} starting...\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 83\u001B[0;31m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     84\u001B[0m         self.model.fit(\n\u001B[1;32m     85\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_dataset\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tf-env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     63\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 64\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     65\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tf-env/lib/python3.9/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1250\u001B[0m                 \u001B[0mmodel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1251\u001B[0m                 steps_per_execution=self._steps_per_execution)\n\u001B[0;32m-> 1252\u001B[0;31m           val_logs = self.evaluate(\n\u001B[0m\u001B[1;32m   1253\u001B[0m               \u001B[0mx\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mval_x\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1254\u001B[0m               \u001B[0my\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mval_y\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tf-env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     63\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 64\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     65\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tf-env/lib/python3.9/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mevaluate\u001B[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001B[0m\n\u001B[1;32m   1535\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprofiler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTrace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'test'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstep_num\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_r\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1536\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_test_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1537\u001B[0;31m               \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtest_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1538\u001B[0m               \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1539\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tf-env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 150\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    151\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tf-env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    908\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    909\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 910\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    911\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    912\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tf-env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    979\u001B[0m               *args, **kwds)\n\u001B[1;32m    980\u001B[0m       \u001B[0;31m# If we did not create any variables the trace we have is good enough.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 981\u001B[0;31m       return self._concrete_stateful_fn._call_flat(\n\u001B[0m\u001B[1;32m    982\u001B[0m           filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\n\u001B[1;32m    983\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tf-env/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1957\u001B[0m         and executing_eagerly):\n\u001B[1;32m   1958\u001B[0m       \u001B[0;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1959\u001B[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[1;32m   1960\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[1;32m   1961\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[0;32m~/anaconda3/envs/tf-env/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    596\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    597\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 598\u001B[0;31m           outputs = execute.execute(\n\u001B[0m\u001B[1;32m    599\u001B[0m               \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    600\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tf-env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     56\u001B[0m   \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     57\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 58\u001B[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[1;32m     59\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[1;32m     60\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# look for the best hyperparameters\n",
    "for optimizer in constants.hyperparameters[\"optimizer\"].domain.values:\n",
    "    for hidden_unit in constants.hyperparameters[\"hidden_unit\"].domain.values:\n",
    "        for batch_size in constants.hyperparameters[\"batch_size\"].domain.values:\n",
    "            for learning_rate in (constants.hyperparameters[\"learning_rate\"].domain.min_value,\n",
    "                                  constants.hyperparameters[\"learning_rate\"].domain.max_value):\n",
    "                for dropout in constants.hyperparameters[\"dropout\"].domain.values:\n",
    "                    for class_weights in constants.hyperparameters[\"class_weights\"].domain.values:\n",
    "                        hparams = {\n",
    "                            constants.hyperparameters[\"optimizer\"]: optimizer,\n",
    "                            constants.hyperparameters[\"hidden_unit\"]: hidden_unit,\n",
    "                            constants.hyperparameters[\"batch_size\"]: batch_size,\n",
    "                            constants.hyperparameters[\"learning_rate\"]: learning_rate,\n",
    "                            constants.hyperparameters[\"class_weights\"]: class_weights,\n",
    "                            constants.hyperparameters[\"dropout\"]: dropout,\n",
    "                        }\n",
    "                        model = base_model.BaseModel(\n",
    "                           batch_pipeline=BatchPipeline(dataset, submission_test_dataset, batch_size),\n",
    "                           parameters=constants.parameters,\n",
    "                           hyperparameters=constants.hyperparameters,\n",
    "                           hparams=hparams,\n",
    "                           class_weights=balanced_class_weights)\n",
    "\n",
    "                        with tf.summary.create_file_writer(f'{log_directory}{model.run_name}').as_default():\n",
    "                            hp.hparams(hparams)\n",
    "                            accuracy, precision, recall, f1 = model.fit_and_evaluate(log_directory=log_directory)\n",
    "                            tf.summary.scalar(\"accuracy\", accuracy, step=1)\n",
    "                            tf.summary.scalar(\"precision\", precision, step=1)\n",
    "                            tf.summary.scalar(\"recall\", recall, step=1)\n",
    "                            tf.summary.scalar(\"f1\", f1, step=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tensorboard --logdir logs/hyperparameter_tuning --port 5000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}