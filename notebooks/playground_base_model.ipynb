{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from KAGGLE_NLP_with_disaster_tweets.model import base_model, constants, utils\n",
    "from KAGGLE_NLP_with_disaster_tweets.data_preparation.utils import DataPipeline, BatchPipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the file: ../data/train.csv\n",
      "-----------------------------------------------------------------------------------------\n",
      "Dataset \n",
      "Size: 7613\n",
      "Dataset examples:\n",
      "Input: [  32  428    1    1 1909 4375    1 1254    7  962  102   66   24 1955\n",
      "    5  314   97    1    1  868  514 1593  314    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "Target: [1. 0.]\n",
      "Input: [   2  111   12  897    2    1    6   33    1    9    2  111   37    1\n",
      " 1921 4897    1   33    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "Target: [1. 0.]\n",
      "Input: [  26  289 2353   14 4020    6 3876 2285 4310   11    1   18 4547   59\n",
      "   11   26    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "Target: [0. 1.]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Getting the file: ../data/test.csv\n",
      "Getting the file: ../data/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "train_file_name = 'train.csv'\n",
    "test_file_name = 'test.csv'\n",
    "sample_submission_file_name = 'sample_submission.csv'\n",
    "\n",
    "vocabulary_size = 5000\n",
    "\n",
    "data_pipeline = DataPipeline(train_file_name, test_file_name, sample_submission_file_name, output_sequence_length=50, vocabulary_size=vocabulary_size)\n",
    "dataset, submission_test_dataset = data_pipeline.prepare_datasets(include_cols=[\"keyword\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True instances: 3271 | 42.965979246026535% of data\n",
      "False instances: 4342 | 57.034020753973465% of data\n"
     ]
    }
   ],
   "source": [
    "dataframe = data_pipeline.dataframe\n",
    "isTrueCount = dataframe[\"target\"].where(dataframe[\"target\"] == 1).count()\n",
    "isFalseCount = dataframe[\"target\"].where(dataframe[\"target\"] == 0).count()\n",
    "print(f\"True instances: {isTrueCount} | {100 * isTrueCount / (isTrueCount + isFalseCount)}% of data\")\n",
    "print(f\"False instances: {isFalseCount} | {100 * isFalseCount / (isTrueCount + isFalseCount)}% of data\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "balanced_class_weights = utils.get_balanced_class_weights(dataframe)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_16 (Embedding)    (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional_14 (Bidirecti  (None, None, 128)        66048     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, None, 128)         16512     \n",
      "                                                                 \n",
      " global_average_pooling1d_15  (None, 128)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 402,818\n",
      "Trainable params: 402,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.6929 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6926 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6924 - accuracy: 0.5000 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6943 - accuracy: 0.5000 - val_loss: 0.6927 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6936 - accuracy: 0.5000 - val_loss: 0.6923 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6925 - accuracy: 0.5000 - val_loss: 0.6918 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6914 - accuracy: 1.0000 - val_loss: 0.6912 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6915 - accuracy: 1.0000 - val_loss: 0.6905 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6900 - accuracy: 1.0000 - val_loss: 0.6898 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6892 - accuracy: 1.0000 - val_loss: 0.6889 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "constants.parameters[\"epochs\"] = 10\n",
    "log_directory = \"./logs/hyperparameter_tuning_BaseModel/\"\n",
    "\n",
    "hparams = {\n",
    "    constants.hyperparameters[\"optimizer\"]: \"adamw\",\n",
    "    constants.hyperparameters[\"batch_size\"]: batch_size,\n",
    "    constants.hyperparameters[\"learning_rate\"]: 1e-3,\n",
    "    constants.hyperparameters[\"class_weights\"]: None,\n",
    "    constants.hyperparameters[\"dropout\"]: 0.1\n",
    "}\n",
    "\n",
    "model = base_model.BaseModel(\n",
    "    vocabulary_size=vocabulary_size,\n",
    "    embedding_dim=64,\n",
    "    hidden_dim=128,\n",
    "    lstm_dim=64,\n",
    "    n_labels=2,\n",
    "    epochs=10,\n",
    "    batch_pipeline=BatchPipeline(dataset, submission_test_dataset, batch_size),\n",
    "    hyperparameters=constants.hyperparameters,\n",
    "    hparams=hparams,\n",
    "    class_weights=balanced_class_weights)\n",
    "debugging_dataset = dataset.take(2).batch(2)\n",
    "model.test_model(debugging_dataset, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run -> __lr=0.001__batch_size=32__optimizer=adamw__class_weights=None__dropout=0.1 starting...\n",
      "Epoch 1/10\n",
      "166/166 [==============================] - 12s 48ms/step - loss: 0.5950 - accuracy: 0.6788 - val_loss: 0.4676 - val_accuracy: 0.7812\n",
      "Epoch 2/10\n",
      "166/166 [==============================] - 6s 33ms/step - loss: 0.3691 - accuracy: 0.8392 - val_loss: 0.5917 - val_accuracy: 0.7696\n",
      "Epoch 3/10\n",
      "166/166 [==============================] - 5s 33ms/step - loss: 0.2714 - accuracy: 0.8893 - val_loss: 0.7292 - val_accuracy: 0.7607\n",
      "Epoch 4/10\n",
      "166/166 [==============================] - 6s 35ms/step - loss: 0.2045 - accuracy: 0.9204 - val_loss: 0.9196 - val_accuracy: 0.7464\n",
      "Epoch 5/10\n",
      "166/166 [==============================] - 6s 38ms/step - loss: 0.1544 - accuracy: 0.9415 - val_loss: 1.0811 - val_accuracy: 0.7491\n",
      "Epoch 6/10\n",
      "166/166 [==============================] - 6s 36ms/step - loss: 0.1187 - accuracy: 0.9597 - val_loss: 1.1586 - val_accuracy: 0.7411\n",
      "Epoch 7/10\n",
      "166/166 [==============================] - 6s 36ms/step - loss: 0.0927 - accuracy: 0.9674 - val_loss: 1.2736 - val_accuracy: 0.7330\n",
      "Epoch 8/10\n",
      " 79/166 [=============>................] - ETA: 2s - loss: 0.0863 - accuracy: 0.9711"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_299581/3874125395.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0maccuracy\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprecision\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecall\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mf1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpredictions1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit_and_evaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlog_directory\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlog_directory\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1-Score: {f1}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/TUM Informatik/WS2122/Applied Deep Learning for NLP/KAGGLE_NLP_with_disaster_tweets/model/base_model.py\u001B[0m in \u001B[0;36mfit_and_evaluate\u001B[0;34m(self, log_directory)\u001B[0m\n\u001B[1;32m     86\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"{self.run_name} starting...\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     87\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 88\u001B[0;31m         self.history = self.model.fit(\n\u001B[0m\u001B[1;32m     89\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatch_pipeline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_dataset\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     90\u001B[0m             \u001B[0mvalidation_data\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatch_pipeline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalidation_dataset\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tf-env/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     63\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 64\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     65\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tf-env/lib/python3.9/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1382\u001B[0m                 _r=1):\n\u001B[1;32m   1383\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1384\u001B[0;31m               \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1385\u001B[0m               \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1386\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tf-env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 150\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    151\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tf-env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    913\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    914\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 915\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    916\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    917\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tf-env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    945\u001B[0m       \u001B[0;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    946\u001B[0m       \u001B[0;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 947\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=not-callable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    948\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    949\u001B[0m       \u001B[0;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tf-env/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2954\u001B[0m       (graph_function,\n\u001B[1;32m   2955\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[0;32m-> 2956\u001B[0;31m     return graph_function._call_flat(\n\u001B[0m\u001B[1;32m   2957\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[1;32m   2958\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tf-env/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1851\u001B[0m         and executing_eagerly):\n\u001B[1;32m   1852\u001B[0m       \u001B[0;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1853\u001B[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[1;32m   1854\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[1;32m   1855\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[0;32m~/anaconda3/envs/tf-env/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    497\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    498\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 499\u001B[0;31m           outputs = execute.execute(\n\u001B[0m\u001B[1;32m    500\u001B[0m               \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    501\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tf-env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     52\u001B[0m   \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 54\u001B[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[1;32m     55\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[1;32m     56\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, f1, predictions1 = model.fit_and_evaluate(log_directory=log_directory)\n",
    "print(f\"Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1-Score: {f1}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history_dict = model.history.history\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# batch_pipeline = BatchPipeline(dataset, submission_test_dataset, batch_size)\n",
    "# predictions = base_model.predict_for_kaggle(batch_pipeline.submission_test_dataset)\n",
    "# print(f\"Predictions: {predictions}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# submission_test_dataframe = data_pipeline.get_dataframe_from_csv(sample_submission_file_name).fillna(\" \")\n",
    "#\n",
    "# utils.create_submission_for_kaggle(\"kaggle_predictions_BaseModel.txt\", submission_test_dataframe[\"id\"].values, predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %load_ext tensorboard"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tensorboard --logdir logs/hyperparameter_tuning --port 5000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}