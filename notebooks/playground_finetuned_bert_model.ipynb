{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "############################################  WARNING   #########################################################\n",
    "# This notebook can not be run currently. The model is not fine-tuned and the implementation for DataPipeline has changed.\n",
    "#################################################################################################################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" # not enough memory in GPU\n",
    "from KAGGLE_NLP_with_disaster_tweets.model.simple_bert_model import SimpleBertModel\n",
    "from KAGGLE_NLP_with_disaster_tweets.data_preparation.utils import DataPipeline, BatchPipeline\n",
    "import tensorflow_text  # required for BERT model\n",
    "\n",
    "log_dir = 'logs/hyperparameter_tuning_bertmodel'\n",
    "try:\n",
    "    # clearing logging directory\n",
    "    shutil.rmtree(log_dir)\n",
    "except NotADirectoryError:\n",
    "    pass\n",
    "\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train_file_name = 'train.csv'\n",
    "test_file_name = 'test.csv'\n",
    "sample_submission_file_name = 'sample_submission.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 23:44:07.866220: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-01-19 23:44:07.866270: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: sersery-asusVivo\n",
      "2022-01-19 23:44:07.866276: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: sersery-asusVivo\n",
      "2022-01-19 23:44:07.866419: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 495.29.5\n",
      "2022-01-19 23:44:07.866442: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 495.29.5\n",
      "2022-01-19 23:44:07.866447: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 495.29.5\n",
      "2022-01-19 23:44:07.866689: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# BERT model has its own preprocessor, so we don't use our own\n",
    "data_pipeline = DataPipeline(train_file_name, test_file_name, sample_submission_file_name, vectorize=False, quiet=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from tensorboard.plugins.hparams import api as hp\n",
    "import tensorflow as tf\n",
    "\n",
    "parameters = {\n",
    "    \"embedding_dim\": 64,\n",
    "    \"n_labels\": 2,\n",
    "    \"epochs\": 3,\n",
    "}\n",
    "\n",
    "hyperparameters = {\"learning_rate\": hp.HParam(\"learning_rate\", hp.RealInterval(1e-3, 1e-1)),\n",
    "                   \"hidden_unit\": hp.HParam(\"hidden_unit\", hp.Discrete([8, 16, 32, 64, 128])),\n",
    "                   \"batch_size\": hp.HParam(\"batch_size\", hp.Discrete([16, 32, 64])),\n",
    "                   \"optimizer\": hp.HParam(\"optimizer\", hp.Discrete([\"adam\", \"adamw\", \"sgd\"])),\n",
    "                   \"class_weights\": hp.HParam(\"class_weights\", hp.Discrete([\"none\", \"balanced\"])),\n",
    "                   \"dropout\": hp.HParam(\"dropout\", hp.Discrete(0.1, 0.2, 0.3))}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "targets = data_pipeline.dataframe[\"target\"]\n",
    "balanced_class_weights = dict(enumerate(class_weight.compute_class_weight(\"balanced\",\n",
    "                                                                          classes=targets.unique().tolist(),\n",
    "                                                                          y=targets.tolist())))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "log_directory = \"./logs/hyperparameter_tuning_bertmodel/\"\n",
    "with tf.summary.create_file_writer(log_directory).as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=hyperparameters.values(),\n",
    "        metrics=[hp.Metric(\"accuracy\", display_name=\"Accuracy\"),\n",
    "                 hp.Metric(\"precision\", display_name=\"Precision\"),\n",
    "                 hp.Metric(\"recall\", display_name=\"Recall\"),\n",
    "                 hp.Metric(\"f1\", display_name=\"F1 Score\")])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " preprocess (KerasLayer)        {'input_mask': (Non  0           ['text[0][0]']                   \n",
      "                                e, 128),                                                          \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128)}                                                      \n",
      "                                                                                                  \n",
      " BERT_encoder (KerasLayer)      {'encoder_outputs':  4385921     ['preprocess[0][0]',             \n",
      "                                 [(None, 128, 128),               'preprocess[0][1]',             \n",
      "                                 (None, 128, 128)],               'preprocess[0][2]']             \n",
      "                                 'pooled_output': (                                               \n",
      "                                None, 128),                                                       \n",
      "                                 'default': (None,                                                \n",
      "                                128),                                                             \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 128, 128)}                                                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 128)          0           ['BERT_encoder[0][3]']           \n",
      "                                                                                                  \n",
      " classifier (Dense)             (None, 2)            258         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,386,179\n",
      "Trainable params: 4,386,178\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "run=0__lr=1e-05__hidden_unit=16__batch_size=32__optimizer=adamw__class_weights=balanced__dropout=0.3 starting...\n",
      "Epoch 1/3\n",
      "190/190 [==============================] - ETA: 0s - loss: 5.2833 - accuracy: 0.5479"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 23:45:01.610163: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 937635840 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 49s 239ms/step - loss: 5.2833 - accuracy: 0.5479 - val_loss: 3.0970 - val_accuracy: 0.5978\n",
      "Epoch 2/3\n",
      "190/190 [==============================] - ETA: 0s - loss: 4.1006 - accuracy: 0.5888"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 23:45:44.910063: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 937635840 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 43s 228ms/step - loss: 4.1006 - accuracy: 0.5888 - val_loss: 3.0030 - val_accuracy: 0.6033\n",
      "Epoch 3/3\n",
      "190/190 [==============================] - ETA: 0s - loss: 3.9113 - accuracy: 0.6016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 23:46:27.844372: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 937635840 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 43s 226ms/step - loss: 3.9113 - accuracy: 0.6016 - val_loss: 2.8319 - val_accuracy: 0.6101\n",
      "23/23 [==============================] - 2s 69ms/step - loss: 3.0603 - accuracy: 0.6073\n",
      "run=0__lr=1e-05__hidden_unit=16__batch_size=32__optimizer=adamw__class_weights=balanced__dropout=0.3 completed.\n",
      "Accuracy: 0.6073369383811951\n",
      "Precision: 0.6846160619936598\n",
      "Recall: 0.5627023470387236\n",
      "F1-Score: 0.5000082272604398\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "parameters[\"epochs\"] = 3\n",
    "\n",
    "hparams = {\n",
    "    hyperparameters[\"optimizer\"]: \"adamw\",\n",
    "    hyperparameters[\"hidden_unit\"]: 16,\n",
    "    hyperparameters[\"batch_size\"]: batch_size,\n",
    "    hyperparameters[\"learning_rate\"]: 1e-5,\n",
    "    hyperparameters[\"class_weights\"]: \"balanced\",\n",
    "    hyperparameters[\"dropout\"]: 0.1\n",
    "}\n",
    "\n",
    "bert_model = SimpleBertModel(batch_pipeline=BatchPipeline(data_pipeline.dataset, batch_size),\n",
    "                             parameters=parameters,\n",
    "                             hyperparameters=hyperparameters,\n",
    "                             hparams=hparams,\n",
    "                             class_weights=balanced_class_weights)\n",
    "\n",
    "accuracy, precision, recall, f1 = bert_model.fit_and_evaluate(log_directory=log_directory)\n",
    "print(f\"Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1-Score: {f1}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensorboard --logdir logs/hyperparameter_tuning_bertmodel --port 5001"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}